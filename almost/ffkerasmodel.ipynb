{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiZvuF_pFK5B",
        "outputId": "a032702f-efa7-4406-9f40-854fb02a2184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n",
            "Setup Complete\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas tensorflow matplotlib numpy pyyaml h5py  &> /dev/null\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%tensorflow_version 2.x\n",
        "print(tf.version)\n",
        "print(\"Setup Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LITXxr3UF1Uk",
        "outputId": "cb9cc7a0-92c2-4d36-89a9-3678c343081d"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = pd.read_csv(\"/content/drive/MyDrive/flamefrontds.csv\", header = None)\n",
        "ds.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "6seTar7_HBZn",
        "outputId": "efd78d73-41eb-4418-8c44-52b0e46a5e61"
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     ...  1272  \\\n",
              "0   609   677   181   175   175   182   182   176   172   169  ...    85   \n",
              "1   612   683   182   183   176   180   179   181   175   167  ...    84   \n",
              "2   611   681   177   176   177   172   178   185   185   173  ...    86   \n",
              "3   591   649   181   179   180   175   168   179   176   178  ...    89   \n",
              "4   683   633   191   178   181   168   174   195   184   180  ...    92   \n",
              "\n",
              "   1273  1274  1275  1276  1277  1278  1279  1280  1281  \n",
              "0    79    73    82    88    83    91    93    87    86  \n",
              "1    77    77    84    79    87    89    83    92   100  \n",
              "2    86    80    78    76    76    83    91    96    93  \n",
              "3    75    90    96    91    81    89    85    81    78  \n",
              "4    89    81    81    78    82    78    89    88    94  \n",
              "\n",
              "[5 rows x 1282 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8417e06b-0f0f-4cd1-bd10-fc4263628d36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1272</th>\n",
              "      <th>1273</th>\n",
              "      <th>1274</th>\n",
              "      <th>1275</th>\n",
              "      <th>1276</th>\n",
              "      <th>1277</th>\n",
              "      <th>1278</th>\n",
              "      <th>1279</th>\n",
              "      <th>1280</th>\n",
              "      <th>1281</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>609</td>\n",
              "      <td>677</td>\n",
              "      <td>181</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>176</td>\n",
              "      <td>172</td>\n",
              "      <td>169</td>\n",
              "      <td>...</td>\n",
              "      <td>85</td>\n",
              "      <td>79</td>\n",
              "      <td>73</td>\n",
              "      <td>82</td>\n",
              "      <td>88</td>\n",
              "      <td>83</td>\n",
              "      <td>91</td>\n",
              "      <td>93</td>\n",
              "      <td>87</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>612</td>\n",
              "      <td>683</td>\n",
              "      <td>182</td>\n",
              "      <td>183</td>\n",
              "      <td>176</td>\n",
              "      <td>180</td>\n",
              "      <td>179</td>\n",
              "      <td>181</td>\n",
              "      <td>175</td>\n",
              "      <td>167</td>\n",
              "      <td>...</td>\n",
              "      <td>84</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>84</td>\n",
              "      <td>79</td>\n",
              "      <td>87</td>\n",
              "      <td>89</td>\n",
              "      <td>83</td>\n",
              "      <td>92</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>611</td>\n",
              "      <td>681</td>\n",
              "      <td>177</td>\n",
              "      <td>176</td>\n",
              "      <td>177</td>\n",
              "      <td>172</td>\n",
              "      <td>178</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>173</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>80</td>\n",
              "      <td>78</td>\n",
              "      <td>76</td>\n",
              "      <td>76</td>\n",
              "      <td>83</td>\n",
              "      <td>91</td>\n",
              "      <td>96</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>591</td>\n",
              "      <td>649</td>\n",
              "      <td>181</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>175</td>\n",
              "      <td>168</td>\n",
              "      <td>179</td>\n",
              "      <td>176</td>\n",
              "      <td>178</td>\n",
              "      <td>...</td>\n",
              "      <td>89</td>\n",
              "      <td>75</td>\n",
              "      <td>90</td>\n",
              "      <td>96</td>\n",
              "      <td>91</td>\n",
              "      <td>81</td>\n",
              "      <td>89</td>\n",
              "      <td>85</td>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>683</td>\n",
              "      <td>633</td>\n",
              "      <td>191</td>\n",
              "      <td>178</td>\n",
              "      <td>181</td>\n",
              "      <td>168</td>\n",
              "      <td>174</td>\n",
              "      <td>195</td>\n",
              "      <td>184</td>\n",
              "      <td>180</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>82</td>\n",
              "      <td>78</td>\n",
              "      <td>89</td>\n",
              "      <td>88</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 1282 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8417e06b-0f0f-4cd1-bd10-fc4263628d36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8417e06b-0f0f-4cd1-bd10-fc4263628d36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8417e06b-0f0f-4cd1-bd10-fc4263628d36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2e5dbf1-fab2-45fe-9e7d-51c6d9ad22bb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2e5dbf1-fab2-45fe-9e7d-51c6d9ad22bb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2e5dbf1-fab2-45fe-9e7d-51c6d9ad22bb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ds"
            }
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "front = ds.iloc[:, [0]]\n",
        "back = ds.iloc[:, [1]]\n",
        "img = ds.iloc[:, 2:]\n",
        "print(front.head())\n",
        "print(back.head())\n",
        "print(img.head())\n",
        "print(img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMWggDIsIs8R",
        "outputId": "3cb06f83-45db-44fe-e474-d33528a2a8de"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0\n",
            "0  609\n",
            "1  612\n",
            "2  611\n",
            "3  591\n",
            "4  683\n",
            "     1\n",
            "0  677\n",
            "1  683\n",
            "2  681\n",
            "3  649\n",
            "4  633\n",
            "   2     3     4     5     6     7     8     9     10    11    ...  1272  \\\n",
            "0   181   175   175   182   182   176   172   169   165   161  ...    85   \n",
            "1   182   183   176   180   179   181   175   167   169   174  ...    84   \n",
            "2   177   176   177   172   178   185   185   173   170   177  ...    86   \n",
            "3   181   179   180   175   168   179   176   178   176   184  ...    89   \n",
            "4   191   178   181   168   174   195   184   180   183   181  ...    92   \n",
            "\n",
            "   1273  1274  1275  1276  1277  1278  1279  1280  1281  \n",
            "0    79    73    82    88    83    91    93    87    86  \n",
            "1    77    77    84    79    87    89    83    92   100  \n",
            "2    86    80    78    76    76    83    91    96    93  \n",
            "3    75    90    96    91    81    89    85    81    78  \n",
            "4    89    81    81    78    82    78    89    88    94  \n",
            "\n",
            "[5 rows x 1280 columns]\n",
            "(463, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_single_column = img.apply(lambda row: ' '.join(row.astype(str)), axis = 1)\n",
        "# front_single_column = front.apply(lambda row: ' '.join(row.astype(str)), axis = 1)\n",
        "# back_single_column = back.apply(lambda row: ' '.join(row.astype(str)), axis = 1)\n",
        "\n",
        "img_data = img_single_column.values\n",
        "print(img_data[0])\n",
        "\n",
        "front_data = front.values\n",
        "back_data = back.values\n",
        "print(front_data[0])\n",
        "print(back_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAiEAY1uK-cO",
        "outputId": "92857c46-fb17-41d1-bfc3-d5bc7861fe1c"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181 175 175 182 182 176 172 169 165 161 174 165 170 170 167 176 182 178 177 179 188 177 180 186 182 182 184 184 182 183 186 187 176 178 183 181 181 182 173 174 174 176 193 187 173 172 184 185 189 200 192 181 186 200 198 191 189 189 188 182 193 207 213 201 199 204 204 191 193 201 210 207 197 203 205 204 201 208 218 208 206 197 196 212 201 204 226 218 206 194 193 206 218 208 205 211 220 222 224 230 222 220 226 223 219 229 236 230 221 219 218 235 250 240 234 227 226 238 252 245 224 217 231 240 236 247 251 245 241 240 243 243 248 244 249 237 252 253 253 256 244 246 255 252 261 264 267 258 241 251 257 257 258 263 259 253 259 263 273 273 254 266 275 275 277 273 275 270 267 263 271 272 267 277 277 276 290 293 288 281 279 286 289 293 294 295 292 285 283 293 306 299 293 284 288 295 296 294 296 290 303 300 306 304 306 308 303 310 307 309 314 304 317 314 314 313 296 302 309 298 317 324 325 325 332 328 324 324 330 329 322 323 338 336 334 324 316 333 347 328 329 327 343 350 334 324 334 351 354 345 345 339 344 350 356 354 338 341 359 355 357 361 359 363 376 368 358 362 384 362 368 369 373 380 390 376 384 368 374 394 389 385 383 377 394 382 375 381 395 385 394 389 394 391 396 391 385 379 391 388 387 408 415 401 393 396 410 414 421 421 414 412 412 417 418 411 411 411 430 435 440 444 451 429 415 424 437 438 437 458 461 455 451 438 436 443 453 443 451 463 462 451 450 458 465 447 438 446 455 454 469 470 461 455 464 468 468 463 459 462 463 449 450 461 469 472 473 464 458 450 470 481 490 472 476 472 465 480 506 499 492 485 499 492 485 483 499 498 496 496 497 488 488 485 501 508 489 485 491 486 500 499 520 518 529 522 517 512 530 532 521 513 511 507 509 511 500 499 518 529 535 510 500 518 532 518 513 527 525 514 538 542 536 527 534 548 548 544 556 555 554 550 557 561 554 560 567 563 562 560 591 589 581 593 598 581 581 590 611 606 594 602 613 608 601 613 633 641 636 648 645 645 647 646 650 661 665 657 665 672 677 674 669 680 686 685 683 703 698 699 713 707 714 714 716 695 711 727 735 734 746 758 766 734 723 732 756 771 770 771 773 775 789 789 777 778 786 785 807 816 813 801 797 808 817 832 829 826 830 841 858 854 847 870 877 876 882 886 880 884 894 909 911 920 918 941 958 942 958 952 952 947 971 1007 1009 1011 1031 1037 1054 1044 1039 1043 1081 1081 1086 1110 1114 1121 1118 1124 1117 1117 1139 1126 1139 1143 1138 1134 1154 1155 1135 1131 1133 1125 1138 1154 1136 1132 1130 1132 1139 1157 1169 1184 1182 1200 1220 1213 1201 1205 1232 1213 1225 1215 1253 1275 1279 1279 1262 1286 1300 1274 1254 1264 1264 1249 1240 1236 1229 1163 1118 1102 1086 1048 1014 984 952 931 922 895 893 884 881 848 829 802 758 738 726 681 656 609 594 572 546 537 520 490 477 443 430 400 366 333 321 282 241 219 212 202 197 199 196 177 166 169 170 167 160 167 172 170 149 148 159 154 145 145 147 151 150 140 137 136 128 137 142 143 147 146 149 145 143 134 133 133 134 131 134 124 132 141 136 139 139 138 132 132 125 133 135 129 133 132 125 122 123 117 122 132 131 119 116 122 121 116 128 129 132 125 118 125 119 112 115 128 134 122 127 129 122 119 119 112 119 115 111 112 115 122 122 109 107 114 116 109 107 113 117 112 109 113 123 117 119 122 115 108 106 107 108 111 107 99 96 101 99 104 103 97 95 101 105 104 113 110 109 111 108 100 95 105 109 101 96 99 105 106 103 104 106 115 119 106 99 99 99 96 100 105 95 102 100 90 93 95 106 113 111 113 111 108 108 108 108 98 97 95 106 104 100 98 106 107 97 97 96 90 103 100 92 98 102 95 97 96 98 93 99 97 103 97 91 96 99 105 101 92 95 89 94 101 106 104 103 98 98 94 99 98 93 91 99 103 94 86 92 91 104 96 89 91 95 100 105 96 98 98 99 101 97 92 104 91 88 95 98 89 92 97 96 87 87 88 92 93 96 99 99 93 90 99 107 100 94 100 94 87 92 103 109 99 94 99 94 98 97 90 89 87 93 93 98 80 82 81 93 101 93 93 93 88 88 93 92 99 102 94 88 90 90 92 99 93 73 85 94 87 88 83 83 90 93 91 89 86 83 80 98 99 100 94 87 86 90 98 96 90 92 106 99 100 105 102 98 89 86 86 92 93 92 85 86 93 90 86 89 81 86 78 90 96 93 88 92 93 88 83 93 98 88 83 86 86 94 95 94 92 97 94 90 85 88 90 86 84 87 89 93 91 87 82 84 92 93 85 86 91 84 86 94 97 100 101 90 86 87 98 89 80 87 89 87 96 90 84 89 92 94 93 92 80 81 84 92 98 95 90 87 82 89 87 90 85 84 90 88 83 87 86 94 94 98 93 88 85 87 94 95 96 94 88 76 73 88 80 73 78 86 90 87 86 100 98 85 78 82 82 87 87 84 85 86 84 83 80 83 81 78 79 90 82 83 82 88 88 91 83 83 81 88 88 90 89 89 95 87 90 101 81 84 78 82 90 86 85 82 83 87 83 84 84 90 89 88 95 90 86 85 86 86 78 73 75 86 92 90 81 88 86 79 80 87 91 95 93 84 88 91 88 89 87 82 85 85 96 85 81 83 88 91 89 76 75 80 91 97 88 83 82 84 81 85 88 80 83 94 90 86 85 99 99 98 93 85 84 85 92 91 80 80 86 84 89 92 86 92 92 91 90 83 86 90 97 95 91 86 88 80 81 86 79 78 84 89 82 77 82 94 93 86 82 79 81 86 91 95 85 85 90 86 87 89 84 84 87 89 94 89 90 85 79 73 82 88 83 91 93 87 86\n",
            "[609]\n",
            "[677]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensors = tf.convert_to_tensor(img_data)\n",
        "front_tensors = tf.convert_to_tensor(front_data)\n",
        "back_tensors = tf.convert_to_tensor(back_data)\n",
        "\n",
        "def convert_to_num(tensor):\n",
        "  split_tensor = tf.strings.split(tensor, ' ')\n",
        "  # change tf.XXX32 to whatever\n",
        "  integer_tensor = tf.strings.to_number(split_tensor, tf.int32)\n",
        "  return integer_tensor\n",
        "\n",
        "img_tensors = convert_to_num(img_tensors)\n",
        "img_tensors = tf.reshape(img_tensors, (463, 1280))\n",
        "\n",
        "print(\"Flame front front: \", front_tensors[0], front_tensors.shape)\n",
        "print(\"Flame front back: \", back_tensors[0], back_tensors.shape)\n",
        "print(\"Image row: \", img_tensors[0], img_tensors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BduS0vwLNj-",
        "outputId": "358566fb-ae43-4def-fe9f-692cecbfe3c3"
      },
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flame front front:  tf.Tensor([609], shape=(1,), dtype=int64) (463, 1)\n",
            "Flame front back:  tf.Tensor([677], shape=(1,), dtype=int64) (463, 1)\n",
            "Image row:  tf.Tensor([181 175 175 ...  93  87  86], shape=(1280,), dtype=int32) (463, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "def parallel_shuffle(tensor1, tensor2, tensor3):\n",
        "\n",
        "  indicies = list(range(tf.reduce_prod(tensor1.shape)))\n",
        "  shuffle(indicies)\n",
        "  # print(indicies)\n",
        "\n",
        "  shuffled_1 = np.empty_like(tensor1)\n",
        "  shuffled_2 = np.empty_like(tensor2)\n",
        "  shuffled_3 = np.empty_like(tensor3)\n",
        "\n",
        "  for i in range(len(indicies)):\n",
        "    shuffled_1[i] = tensor1[indicies[i]]\n",
        "    shuffled_2[i] = tensor2[indicies[i]]\n",
        "    shuffled_3[i] = tensor3[indicies[i]]\n",
        "\n",
        "  return shuffled_1, shuffled_2, shuffled_3\n",
        "\n",
        "front_tensors, back_tensors, img_tensors = parallel_shuffle(front_tensors, back_tensors, img_tensors)\n",
        "print(front_tensors[0], back_tensors[0], img_tensors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zv8N4rRt2Il",
        "outputId": "1e735277-3365-434a-efc0-1c5d9f2fa3a8"
      },
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[557] [635] [246 239 240 ...  99  97  89]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for front\n",
        "\n",
        "train_len = int(463 * 0.8)\n",
        "val_len = int(463 * 0.1)\n",
        "test_len = val_len\n",
        "\n",
        "x_train = [None] * train_len\n",
        "y_train = [None] * train_len\n",
        "\n",
        "x_val = [None] * val_len\n",
        "y_val = [None] * val_len\n",
        "\n",
        "x_test = [None] * test_len\n",
        "y_test = [None] * test_len\n",
        "\n",
        "\n",
        "for i in range(train_len):\n",
        "  x_train[i] = img_tensors[i]\n",
        "  y_train[i] = front_tensors[i]\n",
        "\n",
        "for i in range(val_len):\n",
        "  x_val[i] = img_tensors[i + train_len]\n",
        "  y_val[i] = front_tensors[i + train_len]\n",
        "\n",
        "for i in range(test_len):\n",
        "  x_test[i] = img_tensors[i+ train_len + val_len]\n",
        "  y_test[i] = front_tensors[i+ train_len + val_len]\n",
        "\n",
        "print(x_train[0], x_val[0], x_test[0])\n",
        "print(y_train[0], y_val[0], y_test[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbryDPuWQg_6",
        "outputId": "1b8fcd74-9fbb-4dcc-94bb-e0e2741d71f9"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[246 239 240 ...  99  97  89] [279 264 273 ... 101  87  90] [160 174 163 ...  89  94  95]\n",
            "[557] [589] [711]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import Sequential\n",
        "from keras import callbacks\n",
        "\n",
        "# total # of units btwn input and output\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(units = 512, activation = 'relu', input_shape = [1280]),\n",
        "    layers.Dense(units = 256, activation = 'relu'),\n",
        "    layers.Dense(units = 1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Lion(learning_rate = 0.0005, use_ema = True),\n",
        "    loss = \"mean_absolute_error\",\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cKH06T8TROy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021eedf9-c4a5-42e9-d1ce-14e762e8d5a3"
      },
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_113\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_339 (Dense)           (None, 512)               655872    \n",
            "                                                                 \n",
            " dense_340 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_341 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 787457 (3.00 MB)\n",
            "Trainable params: 787457 (3.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    np.array(x_train), np.array(y_train),\n",
        "    validation_data = [np.array(x_val), np.array(y_val)],\n",
        "    epochs= 256,\n",
        "    batch_size= 64,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXCqyCVcUv7V",
        "outputId": "28a24c20-0d6d-4c44-967a-d6c9a8db1198"
      },
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "6/6 [==============================] - 1s 51ms/step - loss: 939.5295 - val_loss: 334.8753\n",
            "Epoch 2/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 485.1442 - val_loss: 318.8076\n",
            "Epoch 3/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 322.4396 - val_loss: 203.8694\n",
            "Epoch 4/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 222.9156 - val_loss: 148.7697\n",
            "Epoch 5/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 178.2485 - val_loss: 162.4978\n",
            "Epoch 6/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 133.1199 - val_loss: 115.6569\n",
            "Epoch 7/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 119.5852 - val_loss: 101.5072\n",
            "Epoch 8/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 107.9567 - val_loss: 97.9529\n",
            "Epoch 9/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 97.3722 - val_loss: 105.1558\n",
            "Epoch 10/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 100.3182 - val_loss: 100.1444\n",
            "Epoch 11/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 94.6555 - val_loss: 78.9968\n",
            "Epoch 12/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 87.8462 - val_loss: 73.9315\n",
            "Epoch 13/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 82.7398 - val_loss: 76.1181\n",
            "Epoch 14/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 85.3301 - val_loss: 84.7380\n",
            "Epoch 15/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 77.5126 - val_loss: 76.0060\n",
            "Epoch 16/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 72.8861 - val_loss: 73.6545\n",
            "Epoch 17/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 70.9437 - val_loss: 63.9516\n",
            "Epoch 18/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 69.7065 - val_loss: 63.1008\n",
            "Epoch 19/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 71.7167 - val_loss: 59.2516\n",
            "Epoch 20/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 63.2722 - val_loss: 55.8457\n",
            "Epoch 21/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 61.5109 - val_loss: 57.1820\n",
            "Epoch 22/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 65.8736 - val_loss: 60.5935\n",
            "Epoch 23/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 63.6770 - val_loss: 56.8637\n",
            "Epoch 24/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 56.9596 - val_loss: 56.5950\n",
            "Epoch 25/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 59.3602 - val_loss: 53.9646\n",
            "Epoch 26/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 55.3472 - val_loss: 50.7809\n",
            "Epoch 27/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 59.8281 - val_loss: 47.5474\n",
            "Epoch 28/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 58.7383 - val_loss: 48.6686\n",
            "Epoch 29/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 55.3682 - val_loss: 53.5046\n",
            "Epoch 30/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 54.2449 - val_loss: 57.9897\n",
            "Epoch 31/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 54.8892 - val_loss: 55.9519\n",
            "Epoch 32/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 55.7949 - val_loss: 53.6013\n",
            "Epoch 33/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 53.4564 - val_loss: 43.5307\n",
            "Epoch 34/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 51.8223 - val_loss: 45.3728\n",
            "Epoch 35/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 51.7949 - val_loss: 41.9905\n",
            "Epoch 36/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 49.0986 - val_loss: 39.5282\n",
            "Epoch 37/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 52.7832 - val_loss: 41.5963\n",
            "Epoch 38/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 51.4639 - val_loss: 46.5390\n",
            "Epoch 39/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 50.7327 - val_loss: 44.7552\n",
            "Epoch 40/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 48.7242 - val_loss: 39.1097\n",
            "Epoch 41/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 49.5185 - val_loss: 41.9728\n",
            "Epoch 42/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 48.9951 - val_loss: 45.5117\n",
            "Epoch 43/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 49.1549 - val_loss: 40.6429\n",
            "Epoch 44/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 44.6409 - val_loss: 42.0788\n",
            "Epoch 45/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 45.5341 - val_loss: 42.2129\n",
            "Epoch 46/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 46.4495 - val_loss: 37.2262\n",
            "Epoch 47/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 44.0826 - val_loss: 38.0964\n",
            "Epoch 48/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 45.7847 - val_loss: 35.5327\n",
            "Epoch 49/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 44.1101 - val_loss: 34.7207\n",
            "Epoch 50/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 42.7179 - val_loss: 38.2988\n",
            "Epoch 51/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 45.8388 - val_loss: 38.1710\n",
            "Epoch 52/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 43.3963 - val_loss: 38.5746\n",
            "Epoch 53/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 44.2521 - val_loss: 41.1230\n",
            "Epoch 54/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.7509 - val_loss: 34.9426\n",
            "Epoch 55/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.6387 - val_loss: 35.5214\n",
            "Epoch 56/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.2649 - val_loss: 37.2559\n",
            "Epoch 57/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.4085 - val_loss: 35.1049\n",
            "Epoch 58/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 43.5574 - val_loss: 37.3545\n",
            "Epoch 59/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 43.7165 - val_loss: 34.5899\n",
            "Epoch 60/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 43.2321 - val_loss: 37.3788\n",
            "Epoch 61/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.6428 - val_loss: 38.4944\n",
            "Epoch 62/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 41.5682 - val_loss: 38.3392\n",
            "Epoch 63/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 43.3505 - val_loss: 37.1041\n",
            "Epoch 64/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 41.9443 - val_loss: 41.6289\n",
            "Epoch 65/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 42.5232 - val_loss: 36.0849\n",
            "Epoch 66/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.4906 - val_loss: 35.2174\n",
            "Epoch 67/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.8368 - val_loss: 34.4535\n",
            "Epoch 68/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.1102 - val_loss: 30.8502\n",
            "Epoch 69/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.3514 - val_loss: 30.7863\n",
            "Epoch 70/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.0519 - val_loss: 33.2245\n",
            "Epoch 71/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 41.8102 - val_loss: 36.9332\n",
            "Epoch 72/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.2623 - val_loss: 36.6097\n",
            "Epoch 73/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.2730 - val_loss: 29.9998\n",
            "Epoch 74/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 41.2204 - val_loss: 31.0203\n",
            "Epoch 75/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.4200 - val_loss: 29.7774\n",
            "Epoch 76/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.4398 - val_loss: 32.4180\n",
            "Epoch 77/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.0578 - val_loss: 31.6136\n",
            "Epoch 78/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.9433 - val_loss: 35.0399\n",
            "Epoch 79/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.6843 - val_loss: 32.4401\n",
            "Epoch 80/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 38.8194 - val_loss: 30.9620\n",
            "Epoch 81/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.4382 - val_loss: 32.1264\n",
            "Epoch 82/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 37.2582 - val_loss: 34.3194\n",
            "Epoch 83/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 37.4210 - val_loss: 30.5993\n",
            "Epoch 84/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 43.4599 - val_loss: 31.4180\n",
            "Epoch 85/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 37.9455 - val_loss: 32.9396\n",
            "Epoch 86/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 39.3439 - val_loss: 31.9835\n",
            "Epoch 87/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 38.0875 - val_loss: 29.9828\n",
            "Epoch 88/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 34.6774 - val_loss: 25.8997\n",
            "Epoch 89/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 36.2658 - val_loss: 29.0396\n",
            "Epoch 90/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 39.0160 - val_loss: 29.5534\n",
            "Epoch 91/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 37.9711 - val_loss: 29.8401\n",
            "Epoch 92/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 37.0243 - val_loss: 29.5695\n",
            "Epoch 93/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 36.2002 - val_loss: 30.0959\n",
            "Epoch 94/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 37.9200 - val_loss: 30.4809\n",
            "Epoch 95/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 40.1187 - val_loss: 30.4032\n",
            "Epoch 96/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 38.7576 - val_loss: 32.2903\n",
            "Epoch 97/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 37.1339 - val_loss: 32.3878\n",
            "Epoch 98/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 35.2930 - val_loss: 34.8176\n",
            "Epoch 99/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 37.3429 - val_loss: 30.7749\n",
            "Epoch 100/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 40.0151 - val_loss: 28.2582\n",
            "Epoch 101/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 39.7954 - val_loss: 28.6348\n",
            "Epoch 102/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 36.4406 - val_loss: 29.1832\n",
            "Epoch 103/256\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 37.5610 - val_loss: 30.9163\n",
            "Epoch 104/256\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 38.8341 - val_loss: 35.4416\n",
            "Epoch 105/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 36.4172 - val_loss: 32.3718\n",
            "Epoch 106/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.5469 - val_loss: 32.3676\n",
            "Epoch 107/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.6470 - val_loss: 33.0958\n",
            "Epoch 108/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.7606 - val_loss: 33.3325\n",
            "Epoch 109/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 36.7746 - val_loss: 33.1173\n",
            "Epoch 110/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 38.6980 - val_loss: 28.7027\n",
            "Epoch 111/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.3378 - val_loss: 32.7000\n",
            "Epoch 112/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 37.3457 - val_loss: 29.5715\n",
            "Epoch 113/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 34.3168 - val_loss: 27.1205\n",
            "Epoch 114/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.9274 - val_loss: 30.1785\n",
            "Epoch 115/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.0621 - val_loss: 29.6428\n",
            "Epoch 116/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 36.0942 - val_loss: 31.2922\n",
            "Epoch 117/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.6330 - val_loss: 31.5934\n",
            "Epoch 118/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.0505 - val_loss: 32.4412\n",
            "Epoch 119/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 37.6400 - val_loss: 31.6693\n",
            "Epoch 120/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.6792 - val_loss: 32.4604\n",
            "Epoch 121/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 36.9943 - val_loss: 33.2650\n",
            "Epoch 122/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 35.3467 - val_loss: 34.4716\n",
            "Epoch 123/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 34.7567 - val_loss: 29.8197\n",
            "Epoch 124/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.0838 - val_loss: 29.2330\n",
            "Epoch 125/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.6689 - val_loss: 30.7848\n",
            "Epoch 126/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.4617 - val_loss: 31.0077\n",
            "Epoch 127/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.2109 - val_loss: 30.1566\n",
            "Epoch 128/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 34.1977 - val_loss: 28.9819\n",
            "Epoch 129/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.4018 - val_loss: 29.2846\n",
            "Epoch 130/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 33.6681 - val_loss: 28.7199\n",
            "Epoch 131/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.0734 - val_loss: 28.0211\n",
            "Epoch 132/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.3682 - val_loss: 28.4602\n",
            "Epoch 133/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.1773 - val_loss: 28.1761\n",
            "Epoch 134/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.4093 - val_loss: 29.7515\n",
            "Epoch 135/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 34.4583 - val_loss: 28.5778\n",
            "Epoch 136/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.9791 - val_loss: 28.9047\n",
            "Epoch 137/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 34.5299 - val_loss: 28.1485\n",
            "Epoch 138/256\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 33.9911 - val_loss: 29.0441\n",
            "Epoch 139/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 33.8702 - val_loss: 24.4970\n",
            "Epoch 140/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.5777 - val_loss: 26.7159\n",
            "Epoch 141/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.9165 - val_loss: 26.8836\n",
            "Epoch 142/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 31.7157 - val_loss: 28.9238\n",
            "Epoch 143/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.9919 - val_loss: 34.2974\n",
            "Epoch 144/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.2799 - val_loss: 25.7139\n",
            "Epoch 145/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.1069 - val_loss: 25.0348\n",
            "Epoch 146/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.3497 - val_loss: 27.5771\n",
            "Epoch 147/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 32.9574 - val_loss: 26.5541\n",
            "Epoch 148/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.4322 - val_loss: 24.7694\n",
            "Epoch 149/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 34.3236 - val_loss: 25.4307\n",
            "Epoch 150/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.3641 - val_loss: 32.0701\n",
            "Epoch 151/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.7824 - val_loss: 33.9564\n",
            "Epoch 152/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.0908 - val_loss: 30.1470\n",
            "Epoch 153/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.9689 - val_loss: 26.4053\n",
            "Epoch 154/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 33.7310 - val_loss: 24.7436\n",
            "Epoch 155/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 32.9560 - val_loss: 24.6593\n",
            "Epoch 156/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.5968 - val_loss: 24.2385\n",
            "Epoch 157/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.0946 - val_loss: 24.7063\n",
            "Epoch 158/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 31.8722 - val_loss: 29.6111\n",
            "Epoch 159/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.4724 - val_loss: 28.6565\n",
            "Epoch 160/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.3677 - val_loss: 31.3999\n",
            "Epoch 161/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.6842 - val_loss: 30.6663\n",
            "Epoch 162/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.0730 - val_loss: 32.1044\n",
            "Epoch 163/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.2235 - val_loss: 31.3388\n",
            "Epoch 164/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 32.2279 - val_loss: 27.9374\n",
            "Epoch 165/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 31.6934 - val_loss: 30.7305\n",
            "Epoch 166/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 30.7692 - val_loss: 28.7001\n",
            "Epoch 167/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 33.7453 - val_loss: 28.8114\n",
            "Epoch 168/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 30.1299 - val_loss: 28.7197\n",
            "Epoch 169/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 31.1384 - val_loss: 26.5249\n",
            "Epoch 170/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 31.5633 - val_loss: 30.2192\n",
            "Epoch 171/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.0008 - val_loss: 27.4598\n",
            "Epoch 172/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.5395 - val_loss: 25.7107\n",
            "Epoch 173/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 28.7112 - val_loss: 24.7254\n",
            "Epoch 174/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.5019 - val_loss: 26.7762\n",
            "Epoch 175/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.1592 - val_loss: 25.2767\n",
            "Epoch 176/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 31.0764 - val_loss: 23.5371\n",
            "Epoch 177/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 30.7631 - val_loss: 24.3101\n",
            "Epoch 178/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 30.4403 - val_loss: 21.9378\n",
            "Epoch 179/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 31.2153 - val_loss: 24.7933\n",
            "Epoch 180/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 30.9881 - val_loss: 22.2467\n",
            "Epoch 181/256\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 30.7521 - val_loss: 22.1999\n",
            "Epoch 182/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 28.3777 - val_loss: 29.2988\n",
            "Epoch 183/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 31.9223 - val_loss: 28.1981\n",
            "Epoch 184/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.3885 - val_loss: 26.5870\n",
            "Epoch 185/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 30.3507 - val_loss: 26.9215\n",
            "Epoch 186/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 31.1856 - val_loss: 26.3612\n",
            "Epoch 187/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 30.0615 - val_loss: 26.9351\n",
            "Epoch 188/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 32.2693 - val_loss: 23.3443\n",
            "Epoch 189/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 30.9331 - val_loss: 23.8068\n",
            "Epoch 190/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 28.8831 - val_loss: 24.8201\n",
            "Epoch 191/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 31.1474 - val_loss: 23.9966\n",
            "Epoch 192/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 30.6704 - val_loss: 25.9723\n",
            "Epoch 193/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 28.8386 - val_loss: 24.7125\n",
            "Epoch 194/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 30.4100 - val_loss: 26.6036\n",
            "Epoch 195/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 30.0654 - val_loss: 26.3923\n",
            "Epoch 196/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 30.2616 - val_loss: 23.2192\n",
            "Epoch 197/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 28.7252 - val_loss: 24.9010\n",
            "Epoch 198/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 28.3587 - val_loss: 21.1797\n",
            "Epoch 199/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 29.6490 - val_loss: 26.8851\n",
            "Epoch 200/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 30.1427 - val_loss: 24.3335\n",
            "Epoch 201/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 27.3964 - val_loss: 22.8649\n",
            "Epoch 202/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 29.7839 - val_loss: 23.8172\n",
            "Epoch 203/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 30.2968 - val_loss: 24.3782\n",
            "Epoch 204/256\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 30.4648 - val_loss: 20.4790\n",
            "Epoch 205/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 28.8299 - val_loss: 23.5385\n",
            "Epoch 206/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 30.3592 - val_loss: 23.4624\n",
            "Epoch 207/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 28.3197 - val_loss: 26.1253\n",
            "Epoch 208/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 29.6429 - val_loss: 25.1209\n",
            "Epoch 209/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 26.8078 - val_loss: 25.0882\n",
            "Epoch 210/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 29.6663 - val_loss: 21.8828\n",
            "Epoch 211/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 27.5867 - val_loss: 24.7116\n",
            "Epoch 212/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 26.5738 - val_loss: 25.0467\n",
            "Epoch 213/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 30.3438 - val_loss: 23.8178\n",
            "Epoch 214/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 27.2166 - val_loss: 23.8787\n",
            "Epoch 215/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 30.7263 - val_loss: 21.3543\n",
            "Epoch 216/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 29.5546 - val_loss: 23.2211\n",
            "Epoch 217/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 28.9101 - val_loss: 21.3577\n",
            "Epoch 218/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 28.5212 - val_loss: 21.4602\n",
            "Epoch 219/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 26.8018 - val_loss: 26.0941\n",
            "Epoch 220/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 28.8098 - val_loss: 26.0840\n",
            "Epoch 221/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.1435 - val_loss: 28.2920\n",
            "Epoch 222/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 27.1579 - val_loss: 22.5883\n",
            "Epoch 223/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 28.3712 - val_loss: 24.7559\n",
            "Epoch 224/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 28.7739 - val_loss: 24.7575\n",
            "Epoch 225/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 27.8712 - val_loss: 22.5041\n",
            "Epoch 226/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 27.3664 - val_loss: 24.8855\n",
            "Epoch 227/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 28.6918 - val_loss: 24.2792\n",
            "Epoch 228/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 25.9772 - val_loss: 25.1804\n",
            "Epoch 229/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.5931 - val_loss: 22.5783\n",
            "Epoch 230/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 25.1745 - val_loss: 28.2661\n",
            "Epoch 231/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 26.4723 - val_loss: 24.1223\n",
            "Epoch 232/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.4787 - val_loss: 21.0074\n",
            "Epoch 233/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 27.6706 - val_loss: 23.9489\n",
            "Epoch 234/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.8909 - val_loss: 24.6429\n",
            "Epoch 235/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 26.4161 - val_loss: 25.2736\n",
            "Epoch 236/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 25.9245 - val_loss: 25.2747\n",
            "Epoch 237/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 24.9844 - val_loss: 21.4287\n",
            "Epoch 238/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 28.0348 - val_loss: 22.5975\n",
            "Epoch 239/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 27.4551 - val_loss: 23.9738\n",
            "Epoch 240/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 27.5188 - val_loss: 24.6159\n",
            "Epoch 241/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 25.8373 - val_loss: 26.9195\n",
            "Epoch 242/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 26.6722 - val_loss: 23.3151\n",
            "Epoch 243/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 26.9221 - val_loss: 22.0526\n",
            "Epoch 244/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.9783 - val_loss: 27.5414\n",
            "Epoch 245/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 27.3553 - val_loss: 21.0822\n",
            "Epoch 246/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.5287 - val_loss: 22.5012\n",
            "Epoch 247/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 27.1309 - val_loss: 19.7210\n",
            "Epoch 248/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 26.0494 - val_loss: 24.8485\n",
            "Epoch 249/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 25.9449 - val_loss: 21.4586\n",
            "Epoch 250/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 23.7577 - val_loss: 22.9150\n",
            "Epoch 251/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 25.3503 - val_loss: 24.5612\n",
            "Epoch 252/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 25.9215 - val_loss: 23.0287\n",
            "Epoch 253/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 26.0008 - val_loss: 24.1690\n",
            "Epoch 254/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 26.5962 - val_loss: 22.0757\n",
            "Epoch 255/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.5137 - val_loss: 20.1166\n",
            "Epoch 256/256\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 25.8257 - val_loss: 22.1866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], color = 'teal', label = 'loss')\n",
        "plt.plot(history.history['val_loss'], color = 'orange', label = 'val_loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eVx95Nz23s8i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "b956f47e-dffb-4e83-ae58-2029ed4c0da4"
      },
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDOUlEQVR4nO3deXxU9b3/8dfMJDNZJyvZSICAKCCIyBr1qpVcQNGrVVsXtNZypVrodWlty/1VrNqWlvaqF0ulenuF3qvW2rpUrqIUBVQCsriwbwIJSxIgyUz2zHJ+f5xkSIaJECQ5A7yfj8c8IHPOzHzPYcy8/Xw/5zs2wzAMRERERKKI3eoBiIiIiIRTQBEREZGoo4AiIiIiUUcBRURERKKOAoqIiIhEHQUUERERiToKKCIiIhJ1FFBEREQk6sRYPYCTEQwGOXDgAMnJydhsNquHIyIiIifAMAxqa2vJy8vDbv/yGslpGVAOHDhAQUGB1cMQERGRk1BWVkZ+fv6X7nNaBpTk5GTAPEC3223xaEREROREeL1eCgoKQp/jX+a0DCht0zput1sBRURE5DRzIu0ZapIVERGRqKOAIiIiIlFHAUVERESijgKKiIiIRB0FFBEREYk6CigiIiISdRRQREREJOoooIiIiEjUUUARERGRqKOAIiIiIlFHAUVERESijgKKiIiIRB0FlHZWlpVx39tv88f1660eioiIyFlNAaWdDRUVzP34Yxbt2GH1UERERM5qCijtOOzm6QgEgxaPRERE5OymgNKO3WYDIGgYFo9ERETk7KaA0o6jNaAEFFBEREQspYDSjqZ4REREooMCSjsOTfGIiIhEBQWUduya4hEREYkKCijtaIpHREQkOiigtKMmWRERkeiggNJOWwVFPSgiIiLWUkBpJ9SDoikeERERSymgtKMpHhERkeiggNKOmmRFRESigwJKO1rqXkREJDoooLSjKR4REZHooIDSjqZ4REREooMCSjta6l5ERCQ6KKC0o6XuRUREooMCSjua4hEREYkOCijtqElWREQkOiigtKOl7kVERKKDAko7WupeREQkOiigtKMpHhERkeiggNKOmmRFRESigwJKO1oHRUREJDoooLSjdVBERESigwJKO5riERERiQ4KKO2oSVZERCQ6KKC0Y1cPioiISFRQQGlHUzwiIiLRQQGlnbYpHgMwVEURERGxjAJKO20VFNA0j4iIiJUUUNpp60EBNcqKiIhYSQGlHUf7gKI+FBEREcsooLTTfopHFRQRERHrKKC0076Coh4UERER6yigtGPXFI+IiEhUUEBpR1M8IiIi0UEBpR1VUERERKKDAkoYLXcvIiJiPQWUMPrCQBEREespoITR9/GIiIhYTwEljENTPCIiIpZTQAlj1xSPiIiI5RRQwmiKR0RExHoKKGHUJCsiImI9BZQwbRUU9aCIiIhYp0sBJRAI8PDDD1NYWEh8fDwDBgzg8ccfx2j3YW4YBrNmzSI3N5f4+HiKi4vZsWNHh+epqqpiypQpuN1uUlNTmTp1KnV1dafmiL6iUA+KpnhEREQs06WA8utf/5pnnnmG3/3ud2zZsoVf//rXzJkzh6effjq0z5w5c5g7dy7z589n9erVJCYmMnHiRJqamkL7TJkyhU2bNrFkyRIWLVrEihUrmDZt2qk7qq9AUzwiIiLWi+nKzitXruS6665j8uTJAPTr14+XXnqJjz/+GDCrJ0899RQ//elPue666wD405/+RHZ2Nq+//jq33HILW7ZsYfHixaxZs4ZRo0YB8PTTT3P11Vfz29/+lry8vFN5fF2mJlkRERHrdamCcvHFF7N06VK2b98OwGeffcaHH37IVVddBcDu3bspLy+nuLg49JiUlBTGjh1LSUkJACUlJaSmpobCCUBxcTF2u53Vq1dHfN3m5ma8Xm+HW3fROigiIiLW61IF5Sc/+Qler5dBgwbhcDgIBAL84he/YMqUKQCUl5cDkJ2d3eFx2dnZoW3l5eVkZWV1HERMDOnp6aF9ws2ePZtHH320K0M9aVoHRURExHpdqqD85S9/4YUXXuDFF19k/fr1LFy4kN/+9rcsXLiwu8YHwMyZM/F4PKFbWVlZt72WpnhERESs16UKykMPPcRPfvITbrnlFgCGDRvG3r17mT17NnfeeSc5OTkAVFRUkJubG3pcRUUFF154IQA5OTlUVlZ2eF6/309VVVXo8eFcLhcul6srQz1papIVERGxXpcqKA0NDdjtHR/icDgItlYbCgsLycnJYenSpaHtXq+X1atXU1RUBEBRURE1NTWsW7cutM97771HMBhk7NixJ30gp4pdPSgiIiKW61IF5dprr+UXv/gFffr04fzzz+eTTz7hiSee4Dvf+Q4ANpuN+++/n5///OcMHDiQwsJCHn74YfLy8rj++usBGDx4MJMmTeLuu+9m/vz5+Hw+ZsyYwS233GL5FTygKR4REZFo0KWA8vTTT/Pwww/zve99j8rKSvLy8vjud7/LrFmzQvv86Ec/or6+nmnTplFTU8Oll17K4sWLiYuLC+3zwgsvMGPGDMaPH4/dbufGG29k7ty5p+6ovgJN8YiIiFjPZhin3yex1+slJSUFj8eD2+0+pc89+rnnWHvgAP93221cPXDgKX1uERGRs1lXPr/1XTxhtNS9iIiI9RRQwmiKR0RExHoKKGHUJCsiImI9BZQwWupeRETEegooYbTUvYiIiPUUUMJoikdERMR6Cihh1CQrIiJiPQWUMFrqXkRExHoKKGE0xSMiImI9BZQwmuIRERGxngJKmLYKiqZ4RERErKOAEkZL3YuIiFhPASWMpnhERESsp4ASRk2yIiIi1lNACaOl7kVERKyngBJGS92LiIhYTwEljENNsiIiIpZTQAkT6kFRBUVERMQyCihhtNS9iIiI9RRQwmiKR0RExHoKKGE0xSMiImI9BZQwusxYRETEegooYbTUvYiIiPUUUMJoikdERMR6Cihh1CQrIiJiPQWUMG0VFPWgiIiIWEcBJYyWuhcREbGeAkoYTfGIiIhYTwEljJpkRURErKeAEkbroIiIiFhPASWMelBERESsp4ASJjTFox4UERERyyighHGogiIiImI5BZQwdvWgiIiIWE4BJYymeERERKyngBJGUzwiIiLWU0AJo6XuRURErKeAEsaulWRFREQsp4ASRlM8IiIi1lNACaMmWREREespoITRUvciIiLWU0AJo6XuRURErKeAEkZTPCIiItZTQAmjJlkRERHrKaCE0VL3IiIi1lNACaMpHhEREespoITRFI+IiIj1FFDCaKl7ERER6ymghNFS9yIiItZTQAmjKR4RERHrKaCEUZOsiIiI9RRQwmipexEREespoITRUvciIiLWU0AJoykeERER6ymghFGTrIiIiPUUUMJoqXsRERHrKaCE0RSPiIiI9RRQwmiKR0RExHoKKGFUQREREbGeAkoY9aCIiIhYTwEljKZ4RERErKeAEkZTPCIiItbrckDZv38/t99+OxkZGcTHxzNs2DDWrl0b2m4YBrNmzSI3N5f4+HiKi4vZsWNHh+eoqqpiypQpuN1uUlNTmTp1KnV1dV/9aE4BLXUvIiJivS4FlOrqai655BJiY2N5++232bx5M//xH/9BWlpaaJ85c+Ywd+5c5s+fz+rVq0lMTGTixIk0NTWF9pkyZQqbNm1iyZIlLFq0iBUrVjBt2rRTd1RfgZa6FxERsZ7NME78k/gnP/kJH330ER988EHE7YZhkJeXxw9+8AN++MMfAuDxeMjOzmbBggXccsstbNmyhSFDhrBmzRpGjRoFwOLFi7n66qvZt28feXl5xx2H1+slJSUFj8eD2+0+0eGfkAO1tfR+4gkcNhv+WbNO6XOLiIiczbry+d2lCsrf//53Ro0axTe+8Q2ysrIYMWIEzz33XGj77t27KS8vp7i4OHRfSkoKY8eOpaSkBICSkhJSU1ND4QSguLgYu93O6tWruzKcbqEmWREREet1KaB88cUXPPPMMwwcOJB33nmHe++9l3/7t39j4cKFAJSXlwOQnZ3d4XHZ2dmhbeXl5WRlZXXYHhMTQ3p6emifcM3NzXi93g637tLWJAtmRUhERER6XkxXdg4Gg4waNYpf/vKXAIwYMYKNGzcyf/587rzzzm4ZIMDs2bN59NFHu+3522vrQQGzihLT7mcRERHpGV2qoOTm5jJkyJAO9w0ePJjS0lIAcnJyAKioqOiwT0VFRWhbTk4OlZWVHbb7/X6qqqpC+4SbOXMmHo8ndCsrK+vKsLvE0T6g6FJjERERS3QpoFxyySVs27atw33bt2+nb9++ABQWFpKTk8PSpUtD271eL6tXr6aoqAiAoqIiampqWLduXWif9957j2AwyNixYyO+rsvlwu12d7h1l/ZTPOpDERERsUaXpngeeOABLr74Yn75y1/yzW9+k48//phnn32WZ599FgCbzcb999/Pz3/+cwYOHEhhYSEPP/wweXl5XH/99YBZcZk0aRJ333038+fPx+fzMWPGDG655ZYTuoKnu7Wf4tFaKCIiItboUkAZPXo0r732GjNnzuSxxx6jsLCQp556iilTpoT2+dGPfkR9fT3Tpk2jpqaGSy+9lMWLFxMXFxfa54UXXmDGjBmMHz8eu93OjTfeyNy5c0/dUX0FmuIRERGxXpfWQYkW3bkOij8YJPbxxwE48qMfkR4ff0qfX0RE5GzVbeugnA0cmuIRERGxnAJKGJumeERERCyngBKBVpMVERGxlgJKBG2XGquCIiIiYg0FlAjaKijqQREREbGGAkoEdk3xiIiIWEoBJQJN8YiIiFhLASUCNcmKiIhYSwElArt6UERERCylgBKBpnhERESspYASgaZ4RERErKWAEkFbBUVTPCIiItZQQIkgdJmxpnhEREQsoYASgaZ4RERErKWAEoGaZEVERKylgBKBlroXERGxlgJKBFrqXkRExFoKKBFoikdERMRaCigRqElWRETEWgooEWipexEREWspoESgKR4RERFrKaBEoCkeERERaymgRKAKioiIiLUUUCJQD4qIiIi1FFAi0BSPiIiItRRQItAUj4iIiLUUUCLQUvciIiLWUkCJQEvdi4iIWEsBJQJN8YiIiFhLASUCNcmKiIhYSwElgrYKinpQRERErKGAEkGoB0VTPCIiIpZQQIlAUzwiIiLWUkCJQE2yIiIi1lJAiUBL3YuIiFhLASWCmNYKil8VFBEREUsooETgcjgAaA4ELB6JiIjI2UkBJYK4mBgAmv1+i0ciIiJydlJAiaCtgtKkgCIiImIJBZQI2iooCigiIiLWUECJwNU2xaMeFBEREUsooESgCoqIiIi1FFAiiFMFRURExFIKKBGoSVZERMRaCigRaIpHRETEWgooEbi0DoqIiIilFFAiUAVFRETEWgooEahJVkRExFoKKBGoSVZERMRaCigRaIpHRETEWgooEahJVkRExFoKKBGogiIiImItBZQI1CQrIiJiLQWUCNo3yRqGYfFoREREzj4KKBG0VVCChoE/GLR4NCIiImcfBZQI2ppkQdM8IiIiVlBAiaBtigfUKCsiImIFBZQIHHY7sXbz1CigiIiI9DwFlE5oLRQRERHrKKB0QmuhiIiIWEcBpRNtfShqkhUREel5CiidUAVFRETEOl8poPzqV7/CZrNx//33h+5rampi+vTpZGRkkJSUxI033khFRUWHx5WWljJ58mQSEhLIysrioYcewh9lQUABRURExDonHVDWrFnDH/7wBy644IIO9z/wwAO8+eabvPLKKyxfvpwDBw5www03hLYHAgEmT55MS0sLK1euZOHChSxYsIBZs2ad/FF0AzXJioiIWOekAkpdXR1TpkzhueeeIy0tLXS/x+Phj3/8I0888QRXXnklI0eO5Pnnn2flypWsWrUKgHfffZfNmzfzv//7v1x44YVcddVVPP7448ybN4+WlpZTc1SngCooIiIi1jmpgDJ9+nQmT55McXFxh/vXrVuHz+frcP+gQYPo06cPJSUlAJSUlDBs2DCys7ND+0ycOBGv18umTZtOZjjdQk2yIiIi1ok5/i4d/fnPf2b9+vWsWbPmmG3l5eU4nU5SU1M73J+dnU15eXlon/bhpG1727ZImpubaW5uDv3s9Xq7OuwuUwVFRETEOl2qoJSVlXHffffxwgsvEBcX111jOsbs2bNJSUkJ3QoKCrr9NRVQRERErNOlgLJu3ToqKyu56KKLiImJISYmhuXLlzN37lxiYmLIzs6mpaWFmpqaDo+rqKggJycHgJycnGOu6mn7uW2fcDNnzsTj8YRuZWVlXRn2SVGTrIiIiHW6FFDGjx/Phg0b+PTTT0O3UaNGMWXKlNDfY2NjWbp0aegx27Zto7S0lKKiIgCKiorYsGEDlZWVoX2WLFmC2+1myJAhEV/X5XLhdrs73LqbKigiIiLW6VIPSnJyMkOHDu1wX2JiIhkZGaH7p06dyoMPPkh6ejput5vvf//7FBUVMW7cOAAmTJjAkCFDuOOOO5gzZw7l5eX89Kc/Zfr06bhcrlN0WF9dnJpkRURELNPlJtnjefLJJ7Hb7dx44400NzczceJEfv/734e2OxwOFi1axL333ktRURGJiYnceeedPPbYY6d6KF+JSxUUERERy3zlgLJs2bIOP8fFxTFv3jzmzZvX6WP69u3LW2+99VVfultpikdERMQ6+i6eToTWQVFAERER6XEKKJ1QBUVERMQ6CiidaAsoapIVERHpeQoonVCTrIiIiHUUUDqhKR4RERHrKKB0Ql8WKCIiYh0FlE6ogiIiImIdBZROxOm7eERERCyjgNIJNcmKiIhYRwGlE5riERERsY4CSifUJCsiImIdBZROqIIiIiJiHQWUTiigiIiIWEcBpRMuXcUjIiJiGQWUTrT/Lh7DMCwejYiIyNlFAaUTbU2yAC1qlBUREelRCijtHXgHlv8LbH0qVEEB9aGIiIj0NAWU9up3w/43ofQvONtVUBRQREREepYCSnu9rzH/PLwKW/MhrYUiIiJiEQWU9hLyIW0EYMD+/9OlxiIiIhZRQAnX+1/MP/e/qUuNRURELKKAEi7/WvPP8ndJiTEvL25UQBEREelRCijh0i6C+Dzw13N5/B4AGnw+a8ckIiJyllFACWezQdYVAAx3lQNQ19Ji4YBERETOPgookThTAXA7zKmd2uZmCwcjIiJy9lFAiSQmETgaUFRBERER6VkKKJG0BpTktgqKAoqIiEiPUkCJxJEAQKLdbI5VBUVERKRnKaBE0lpBSbCZwUQ9KCIiIj1LASWSsICiCoqIiEjPUkCJpDWgxGFWTtSDIiIi0rMUUCIJCyiqoIiIiPQsBZRIWptkY1VBERERsYQCSiStFRRnsAlQBUVERKSnKaBE0hpQYoKNgAKKiIhIT1NAiaQ1oDhaA4ouMxYREelZCiiRtAYUu9GCg4AqKCIiIj1MASWS1iZZgAS7j9qWFgzDsHBAIiIiZxcFlEgccYANgESbD38wSEsgYO2YREREziIKKJHYbKFpnkR763L3muYRERHpMQoonWkNKOkx5tSO+lBERER6jgJKZ1r7UDJdZkDRlTwiIiI9RwGlM60VlAynKigiIiI9TQGlM21TPLFBQD0oIiIiPUkBpTOhHhTz6h1VUERERHqOAkpnWgNKSkxrBUU9KCIiIj1GAaUzrU2yKaqgiIiI9DgFlM60VlCSHT5APSgiIiI9SQGlM6GA4gdUQREREelJCiidCa0k21pBUQ+KiIhIj1FA6UxbQLGZAUUVFBERkZ6jgNKZ1ibZBJtZOVEPioiISM9RQOlMawUl3mYGE1VQREREeo4CSmdaA4oLBRQREZGepoDSmdaA4jSaAE3xiIiI9CQFlM60BpTY1oCiCoqIiEjPUUDpTGuTbGywEdBlxiIiIj1JAaUzrRUUR2tAUQVFRESk5yigdKY1oNhbA0q9z0ez32/liERERM4aCiidaQ0oNn89cTExAByorbVyRCIiImcNBZTOtAUUw0+/5HgA9nm9Vo5IRETkrKGA0pnWJlmAAW4XoIAiIiLSU7oUUGbPns3o0aNJTk4mKyuL66+/nm3btnXYp6mpienTp5ORkUFSUhI33ngjFRUVHfYpLS1l8uTJJCQkkJWVxUMPPYQ/2vo7HE6wmVM7/ZKdAOzXFI+IiEiP6FJAWb58OdOnT2fVqlUsWbIEn8/HhAkTqK+vD+3zwAMP8Oabb/LKK6+wfPlyDhw4wA033BDaHggEmDx5Mi0tLaxcuZKFCxeyYMECZs2adeqO6lRpnebpm2AGFVVQREREeobNMAzjZB986NAhsrKyWL58OZdddhkej4devXrx4osvctNNNwGwdetWBg8eTElJCePGjePtt9/mmmuu4cCBA2RnZwMwf/58fvzjH3Po0CGcTudxX9fr9ZKSkoLH48Htdp/s8I/vtd7QeICX8hdy2/u7uWnIEF75xje67/VERETOYF35/P5KPSgejweA9PR0ANatW4fP56O4uDi0z6BBg+jTpw8lJSUAlJSUMGzYsFA4AZg4cSJer5dNmzZ9leGcerHmyesdFwRUQREREekpMSf7wGAwyP33388ll1zC0KFDASgvL8fpdJKamtph3+zsbMrLy0P7tA8nbdvbtkXS3NxMc7uVXL09FRTissC7lbxYc7l7BRQREZGecdIVlOnTp7Nx40b+/Oc/n8rxRDR79mxSUlJCt4KCgm5/TQBcWQBk2s3m2IO1tQSCwZ55bRERkbPYSQWUGTNmsGjRIt5//33y8/ND9+fk5NDS0kJNTU2H/SsqKsjJyQntE35VT9vPbfuEmzlzJh6PJ3QrKys7mWF3XZxZ2XEbHhw2GwHDoKJdQ7CIiIh0jy4FFMMwmDFjBq+99hrvvfcehYWFHbaPHDmS2NhYli5dGrpv27ZtlJaWUlRUBEBRUREbNmygsrIytM+SJUtwu90MGTIk4uu6XC7cbneHW4+IMyso9uZKcpKSANivaR4REZFu16UelOnTp/Piiy/yxhtvkJycHOoZSUlJIT4+npSUFKZOncqDDz5Ieno6breb73//+xQVFTFu3DgAJkyYwJAhQ7jjjjuYM2cO5eXl/PSnP2X69Om4XK5Tf4RfRWsFheZK8t1j2F9byz6vl9G9e1s7LhERkTNclyoozzzzDB6PhyuuuILc3NzQ7eWXXw7t8+STT3LNNddw4403ctlll5GTk8Orr74a2u5wOFi0aBEOh4OioiJuv/12vvWtb/HYY4+duqM6VVorKDRWkN9atVGjrIiISPfrUgXlRJZMiYuLY968ecybN6/Tffr27ctbb73VlZe2RrsKSu/kZECryYqIiPQEfRfPl2mroDRVqoIiIiLSgxRQvkxbBcVfR5+kWEAVFBERkZ6ggPJlYpLAEQdAv7gWQBUUERGRnqCA8mVstlAVJd/ZCJgB5St8fZGIiIicAAWU42ldTbaXw1ygrcnvp7qpycoRiYiInPEUUI6ntVHW2XKYzIQEQNM8IiIi3U0B5XjaGmXrdzO311tcEb9bq8mKiIh0s5P+NuOzRtulxluf4lZnA30yCtjs/b61YxIRETnDqYJyPG0VlEADAAUxHl1qLCIi0s0UUI6nrYLSKjemjv2eGmvGIiIicpZQQDmetgpKq1hbkNra/RYNRkRE5OyggHI8YRUUgEC9AoqIiEh3UkA5nsS+5oqyrgyaEwcC4Gg6YPGgREREzmwKKMcT64YJq2DCKuzucwFwB49Q39Ji8cBERETOXAooJyL1fEg+h9jEfAB6x9TqSh4REZFupIDSFfG9AciLqdVqsiIiIt1IAaUrEvIA6B3j1WqyIiIi3UgBpSvaVVBKPR6LByMiInLmUkDpivjWCoqjliVffGHxYERERM5cCihdkWBWUHrFNFBSuktVFBERkW6igNIVznSwuwDIddTy0oYNFg9IRETkzKSA0hU2W2iaJy+mlhcUUERERLqFAkpXtV7J09dZz4bKSj4rL7d4QCIiImceBZSuar2SZ0JuPADz1661cjQiIiJnJAWUrkrsA8DEjHoA/ufzz/E2N1s5IhERkTOOAkpX5V0NQK7nH1yQmUq9z8efPvvM4kGJiIicWRRQuqrXZRCXg62lmp8PCQAwb80aDMOweGAiIiJnDgWUrrI7oM83AJgYu44kp5MDVfvYt+SbsPNZiwcnIiJyZlBAORl9bwHAeeBNvjfifP6z19sUHP4rfPxd2DzH4sGJiIic/hRQTkbmOEjoA/5aHvfN5Nvudj0on/6Yt//xuHVjExEROQMooJwMmx3G/AFiknHWbgbgN9UX81T1WHPz7oX8dfNmK0coIiJyWlNAOVl5k+CqTyBnArUZ4/lN7USWcikARXH7+NZrf2P9wYMWD1JEROT0ZDNOw8tPvF4vKSkpeDwe3G631cMBoK6lhQSHDdvf0rD56xm29158yUNYN20aiU6n1cMTERGxXFc+v1VBOUWSnE7sjlhsGeY0z+TUSrYdOcKD77xj8chEREROPwoop1qvSwC4b0AQG/Ds+vU8WVLCfo+HP7//LKVHNO0jIiJyPAoop1rmxQDkNn3Gz6+8EoAH332X3y6cwi0Hv8uON6+iJRCwcoQiIiJRTwHlVMssAmxQ9wUzR57DQxdfTJq9gYfTlgIw3vkZf33/99aOUUREJMopoJxqzhRIHQqAbddz/Lq4mJIx+0l3NGFgA2BQ2a/YfviQlaMUERGJagoo3WHgveafGx7B9l4x51W9ZP5c9L/UG3Fc5DrA/jcvY8+uJdaNUUREJIopoHSHgffC+f/P/HvFe2AE4Zx7sBXehv/C3xAwbHzNtZW8VVfxn289w8bKSoKGwYq9e/nlBx9wpKHB2vGLiIhYLMbqAZyxLngcnKlQuwsG3gNpwwFIOX8GVb0uZ9c732C0Yxt99/0nw9ZUkhgbS73PB8DaAwd49eabLRy8iIiItVRB6S42Gwz+IYx5JhRO2qRnDWPEta9hYOf6pG2MTaik3ucjITYWh83Ga1u38v7u3QAEDYPXt27lE61KKyIiZxEFFIvEpA7G1u9WAFae/yH7Jvo4eM9N3DNqFAD3LV5MqcfDna+/ztdffpmLnn2Wry1cyLbDh60ctoiISI/QUvdW8m6Dt4ZDsNn8OTYV76jn6feXbVQ3NQHgtPn5VvLnfNaSx5qmHM7LyAgtnx80DOw288qg7UeOkJOUhNvlsupoREREvlRXPr8VUKxWsxH2vQFlr0L1esBGaf50bt85jLrKdTyf/SbDXQcxbA4e80zmd4fPY1TfweysqaPZ7+flm27iL5s28dTq1diAC3Ny+FVxMRP694fdC8HmgD7fBIeCi4iIWEsB5XQUaIZ1/wY7nzV/jkkGf635d7vraJUFqA/G8ruaMcyuvhRPMP6Yp7IR5B+D13Cl/21zf0c67zqu5lX/FUwaMpqbhw4lxq7ZPRER6VkKKKezvX+BNfdASzXYndD7Whj1tFlh2fAoNB9d4M1DMtMOTuRv9UNZcP3XGV9YyOwVyxhe+ghTUz4haEB5IIm8mDoA6oKxXHPgNva6RnDb0KFcXFBAjN3O6N69SY+P552dO3l31y4uys3lsr59yXe7sbVOIYmIiHxVCiinu+Yj4N0KaRdCTGLHbcEAHHwbPv0xeDYDUJUxifTLngdXBpR8G/a+SBA7M+vv4B3fSO7K2MHNtv8jx/8Fn7fkMXzv3cDR4OF2ufjn/v3525YtHV4qMTaWrxUWMnXECIKGwYHaWrITE0mJi6PJ72d0Xh65ycndey5EROSMoYByNgi0wObZsPHnYPgh1g1GAPz1YIuBS16CPjcd3b/pMPy9H/jrWd7v98zdl8HemhqqGhvZXVMT2u2GwYMxPFuoqd7L8sYCgl9yoVeS08mbt97KFf360eDzsaGigoBhUJSfj81moyUQIMZuDzXyAvgCAYKGgStGS/CIiJxtFFDOJtWfwaq7oPoT82dXJox7Hnpfc+y+638IW/8D3OeBIwFikwmO/gMv7GnmxY0bmXbRRXw9vRyWXQ2BJnyuHF6P+SY/3tOfzIQELnT7mOp7hkzjCN/1fJulR1y4HA4K09LYfuQIwda30gXZ2fROTubdXbvITkriuvPO4+uDBtHg8zHj7bfxNjdz39ixDMrM5Ivqakbk5DC+f3/iIoSWyvp6Pq+ooL6lBZvNRm5SEkOzsoiPjQ3t0+Dzcai+nj4pKVEzJWUYBmVeL31SUqweiohI1FBAOdsEfVC5AuKyIOV8sHVS9Wg8CG8Udmi4xREPw35mLs9/4G0z7AQazCqM4Tf3Kfof82qgtTOgpQoAIy6Hhc1Xkla7jjRHI3VBJ3MbruajhhzqWlpOaNgJthauTNjN+w39CDoSGZufT77bTanHQ3VjI7UtLexpV91pk5eczDu3347L4eBXH37IK5s3U9vSwt299tA3KZYFnqGc3yuLbw0fzu7qarYePky/1FTOy8xkUGYmvZOTsdtsvLFtG+sOHKCooIDze/Xi0/Jyqhobcdjt9ElJ4dyMDJwOBzF2O5kJCSS0hqL/276dB999l9uHDeP/XXYZvtZKkaO18ThoGNzy17/yyubN/Pull/KL8eNP6HyIiJzpFFCkczv+YDbc9r4W9v8dylu/sNDmMKeIAHInwaUvw+c/g21Pdnx8+kgItkDNhmOfOzYFb9GrvL59Nx7cXDn0cko9Hl7bupUPtq9luG0rk889j3NSk9n4RQk3OJaSYfOytqUfF++9HV8n37xwXkY6afEJBIJBvqg+QnagjCuSKiDoozoQw9qmPL6V/Dk/zVgBwA8OTeCJmotPzflqZ3BmJvePG8cD77xDQ+vXElyQnc2uqipsNhuzx4/ne6NH88sPPuDh998PPe6BceM43NCAw27na/36cf2gQaH1ahp9Pv5r/XoO1NZyUW4uo3v3pm+7SlBFXR3PrF3Lc+vXExcTw7+cey7XDRrEpX36hK7EavT5mLt6NU+uWkWDz0evxER+WFTEPaNG0eDzUbJvH2v272dYdjaTBw7k84oK3tu9m+ZAgLzkZL4+aBDJLheGYVCybx8r9u4l2emkt9vNyNzcLjdLN7SuiiwiEk4BRU6MEYTd/2NeHVS/G5zpcM53YejDEBNvbv/wm1D2N7PScv6/w+Afgc8DJXeYlZu8qyCxH2z7Tzj04dHnttmh8NvQ/y5oPoyx+l+xtRzpdCjVve+gxDaWdM9Kzm/+kKAznUPZN9GnYTXOQ8tgwFRIH0Xgs5/iaNhz3ENbHHcbL1WkEHAPpjBnCKW1tWw7fJithw/jaW4GDGblbmaqex3VLQE+bsjmL847yXBn4QsG+aK6ml1VVQQNA18wSEvADG9p9gbqgk7Oz8lny6FDNLfeH8k/9+/Pki++OOb+fLeb3111FWVeL79ZuZJSj6fD9syEBIZlZRFjt/Pe7t0EIvwnmh4fzy1DhpCTGMcz6z/jYF3dMfsMSEtjr8eDPxhkuPMg+/xuXIk5HKit7bBfYmwsg3v1oqqxkS+qq495notyc5l39dUYhsGqffvol5qK2+Vi7YED7KiqoryujosLCrhh8GDuWbSI5Xv3kpecTF5yMp6mJgZmZPDNIUMYlZdHYVpah/Cyt6aGn69YQUFKCpPOOYeRubmhSlS4Mo+HbUeOhKYC61payE1KYkivXjT6/VQ3NpIWH0+y09khUO33elm9f39o35S4uIjPLyLdTwFFuibQAt7NkHyeGUw6bGuGfa9DZhEk9un8OXxeeP8qOLzSDDqtU0EdJA2A+BywxUJcL8geb/75wY1dGq7hSGCP41zi4jPIiW3CVrXGnI4a+TR4t8D233V8QFw2XPQktH61QEv9QVh3H859r3Tcr/+3zf6dDsffhFG3lyO2DD5a8gBXN73IEcONe9RsdrivYtHOvUwozKd22wKSy55nW3Ma/3Z4MtPGjWf2167gmXd+x76KrWTmjeOQPY+XN2/p0JQMUOB2M3HAAD4pL+fzigp8wWCH7ePy83lg3DicDgcfbPmQtXs2U2h8wf9L/4AMRwN3lN/A5zGj+MWVV3JxQQGLtm9n5tKlNPn9gMGTuSXcn/QunqCLmYfHs6qpL8V9sjjXWUVtzW4am2oIGHaqg3G83jiCkQNG4g5W4/WU8lq5M2JACpdsb6IwpoZ9fjc1wTj6x1YzxHmIoc5KLokvZYSrnLk1Y/lV9aVkJ5pB4ZKCAp5Zu5YjjY2h50mPj2fCgAFMHDAAG7Bi715KvV721tSwoyrCewqw22yh/ieAWLudjIQEMuLjccXE8MnBg7RtdTkcPHrFFdzaJwbX2mm86xvB7MNjGNKrFxdkZ9Pk9+Ow2chMSKDe52Of18uGykoO1tYyNDOdm1L3cHFgBbXOPvwj8Q42Hqlhd3U1cTExZCYkcF5GBjabjb01NSQ6nRS43YzLz+f8rCzKPB5e37qVv27ZQlZiIjeffz4jc3LIS7ATdCTiDwbxB4OkxMWRFheHzWbDFwjwzNq17KqqYtbll5ORkBA6Tn8wSElZGav372ef18vw7Gy+feGFoXBmGAYNPh+JTudx//3CNfn9HKytDU13hgsEg9Q0NXUYj8iJUEARawT9ZlBxpcOhEtgyB6rWQvNhGDANRsyJvKLt5jnmvnHZZg9Nn2+Adzvsew1Sh0HOP8OmX0LdF2YFZ8iPIKbdL0Z/o1nVic8xL8Pe8XuoXA6eTVC74+jUVd7VEJtirtzb1mdzwePm5dlr7jErRgPvNY8hId8cz5bfQuOByMcbkwQpQ6HmMwgc/ZANJhZiTzkfqj6Gpsqj+yfk09xvKjNLB/LcplKGZWVx85DB3D2skIRADTQfpiUIO71NlB3aTaDhIKPS7WQ5DcCA/W9C1bpjhmFgIzD0Z8QMeSgUMHdXVbFz9zLG1f2V5P0vnfg/YVwu9mGz4NOZ4KuhKf9WHjwyiWc+302+K8CMPh7KGsHh83BbyhYKHZUkGHUkBY5+R5Rhi8HW1r8U5jfVF/P7mtFkOhq4LmkrfWM85CU4aIzN4e3DCfyjNpftvgxcNj9+w04AR+ixdpuNczMyCASDGBgMdtWwraaJ7Y3me8rpcIQqXeEuyM7mSEMD+2tryXN4WVnwR/rGevAZdobu/R7bfZlfel6cNj/v917AxfH7Qvd92FjANw5+k/LAl19qH4ufvJhaSv0pXB6/l5+kfUisLcBBfzKXxe+lINbLIX8CHzT14YFDk7Bh8K3ULTTGD+DtxkFsOmxWtfLdbu644AI+r6igpraS/k1r+bs3v8NijfeNHctvJ0xg2Z49/Pgf/2D9wYP0S01lWFYW6fHxpMXFkeR0ssfjoczjIT42liSnk2Snk5G5udw2dAiPLv+AeWvX4m8Nypf37ctFublsO3KEnMRE+qam8vynn7KnpoYBaWlce+653D1yJJsPHeKFDRtwOhz0TUnhxsGD6Z+Wxls7duBpbiY1Lo5AMEjQMLiiXz8GpKeb7xfDYGdVFbtraqhtbqa4f39S4uIor6tj7YEDHKitxdvcjD8YpCg/n1F5eby/Zw+NPh+Tzz2X+JgY9tfWkpOURIzdTqPPx6GGhg7BqrqxkTe3b2fSOefQKyGBlzZuZFdVFUUFBQzNyiIrMbHD1YbtGYYRNc33ZwIFFIkuhmF+u/NXfY5gS9eX7A80wabZsPFxoN1bPX00jPxP6FVk/vz5z2Djo5Gfo61hOCbJfIzPc2xwSciH/t8xv16gfu/R+2NTIXkgeDYeDTEJBRhjnsO267/MEGZ0Pk0UcSyudDNoDfhXqN0Ju54zt8XnQVKh2QzdWG6GsDYj55rHv+1pCNSbqxMnnwMJBeaqxQTNfiTvtmNfMzaVpj634dr/N2xNFZ0OzR+TQoy/dbrKEQfuwZAyBNJHga8WNsw6oUMM4MBBAL9hx+vIojm+D0Z8HpkxPpxGgzlez2ao22m+bnwf7HY79qCPQGJ/fNhxeDfjiR/MR31+w/D8gfRz1WO0eCn55CVyy35PYczRakx5ypU87/4ZO48cYbh9O8mBQ3zmz8cT25e85GSG9OrFZYefpKB8AY0k8L4xlstZRaKtkTp7Gqv6/Qf740ZwsK6ObUfMacy+KSk0+nwcqNrPfY2PMMpZSn0wlkS770uP3Rt04cRPnN18T1T6E/AaCTjsZjVlc0sv/lo3hEfTlzHAWc3hQCKvx97MJ/H/zO8/Nf/tYux2kqinJhhH+/WOjufSuL0s7v2/1AadfNTUh8UNg/hHQz/ibc34DAf7/G6S7c0k21v4wpd2ws8di594u5/6YGyHwDkgLY2cpCR219TQ0lCOJ+DCh1mJaluXKVLgtHH0v+S0uDicDgcV9fUMTE/nrgsv5OmPP+ZgXR1XFhby7eHDyU5K4ruLFrGnpob0+HguyM5m2Z49HZ4zxm4nLzmZwtRUrh80iITYWP74yXp6163iX+I+4fP4YgYMvonNhw6x8dAhKuvrSXY6GZ6dzYD0dBJiY1mxdy81TU18f8wYLunTh6VffMHg+HouqPoT9LsNT/JIVpaV8UV1NfU+H/UtLTQHAozIyWHSOed0mHosr6vj92vWEAgG6e12Y7fZSHY6ubpvJmlxcVQH4znc0MDhhgY2lm3GVrWGuvQrSEtIotHvJz4mhqzERIZlZ5N/gp+RzX4/Ww4fZlNlJf3T0hjXulzEqaaAIhLu8MdmVcXwQ9pFkDuhY2gK+mH9g2boSLsQ6naZVZw+N8HA75lTVrGpR6fAjCBUrTcX1EsfCe5B5vM1V8EXC8wP6NRhkDkO7LHmVFnZ32DDz8yqTjhnmnmJuBEAfx04M8yKUFwOxCab96ecD/1uN6fF2hiG2Uf0+U+hoazjc9qd5uXmA78HOSdwJVFLNSy/Fg59BIV3woDvwNrvQ83nR/dJ7Nc6HgPy/wWyrjADU2Kh+aevzjxX8b3B7uj4/F8sNNfuqdttnpO8yZAx2gxLdV+Y30V1eHXHq8y+jN1p9kHxJb/C0i40G8DDKk/B+N7Yx/4XLL/GPLd9b4WGUvPY2x9r35vNY9oxz7zv8v+D3leDdwd8eKPZLG5zmNW53Imhy/dx9TK/qmLjz+HI6qPPaXPAOfeYx91QBukjMdJHY6vbab7/DpcA0JgyEnvdLlyBmk4PzbA5sLWFW0cCe+LH8Ke9BpMSdzAm7gBVtl44+n2TbQlXsqE5E1vdF5T53VT4XAxKaGZUzHb2JFxKdcBJbf0Rpuy7nQJH5Gm0cPsSRhP3T39mZWU9Sz5djPfgSuwxCRQNHM2YwEck1X7GMk8qhhHgNvcmEm3NBA0bH9nG8FTLzdQd+pRMRx0v157PNYnbeSX3FaqMZObWT+DJioE0Gk7sBPlaViwjUoJ44gbgDbp4Z9cuapqaKHAn8zXXdqa63ibJ1sLa5jyqAvHUBl08772QgwE3l8TtZYSrnFRHE1/40ihp7ofX76DBiCVoj2fyueey/uBB9tbUhN5BTpufub3eZnLCdpy2AFkxZshvCMZw2b678Bt2xsbtB2CrL5MVjX3pHeNlcsIOqoNxNBqxDHVWUh2I5+/15/J+/kLOcx7BZzi4u+JaFtZeaL61bM0Mdh5mQGwVA2KryY/xkhAbQ31sLp+m3Mwr2/dQ09QEGPSNqWFAbDU3JG1hqvsTAtiZVnkNL9ZeQJajjpKC/6J/bA2/qb6YHx2e0OHfKcNez03p+ykJjiAtOZN7R40iPdZgy9Y3WV/rYl1tArGBOgxfLZ96O/732jclhemjR/PQJZec0HviRCmgiESrlmr44CaoeM+s4ox5BlIvMD+wv4pAE+z/P8CA+Fwz2MTnHdtTdDzBgNkwnTTADFxGEEpfgZ1/gKyvmdNrX/WLJ42gGXDCAwyYQa6p0lx40F9vBpf63dCw3wxxse7WacRMMxAYfqj+1AwrNocZ/oI+Myyt/ldzehHMbbFuMzgN+I7ZvO1MhXUPwLanjr6+Iw5Sh7dO2zV1HNt5D8DIJ47+7K+Hj++FPf/z5cfrTIcr3wV7nPmaCb0j7xf0w+4/mf92eVeZQa3qk6MVNsNn/lvs/hPkTIAx882ft82F2u1fPobQ8cVD/nXmdKG/3pze7D/VDFoH36bR2ZumUc+SVrvWfG7vFrNaF2w298dmNsAbAfM9GzT7nE7W4cSLSGvcgiN4dIrUb3OxjzwKbAdxBFv/DVy9YNx/Eyj7O5S+jB0DW9t3lYVptCURTB9J4pHlEbf7cODtfTsZuaOh7FWCrl4cyb6Jg4FkUrY+St+GktC+QUcCvrgCXPXbaDZicdk6VsAqY/qS5t9PLMdOafoNOzG2IM1BB67WitirTaOpSziXbwT/RjxNxzwGYH1TDr/3jOb69ENc6txOqhE5NK5oKqSXo4nBsQdD9z1j3IHb3sLeQAbv1hXwh7jfcp7zCDta0nmqZhxXJuzmqoQdJNjN8Zb63PSOqcVhM1je0JcFDZewK+lyDh/eyZ0JK4npexM/uPb+iK9/shRQRKJZMGBO+aQMjfwhLaeGZyt8NhPSRphVpLgIfSZGEPYvMv89gn7zarGE3uBvgH1/h4OLzWCUfhH0vS3yv5dnM+z9s1lpCvrMKcCmQ2YlJbEfDJ0FaRecuuMKnzI1DLPXq3KFOQb3IOg3xazwlf7FXE7AX9/xC0jhaNhrb/z7kH3Fsa9lGOZxORLM0PjRN48uNRCTaFYlgy1mmMy8xAxB1Z+YIa/vrZAxxjzHH3/XvN+VYW7z15vPkTMBek+GrU9C/Z6jr2+PBUci+GqOPQ92J5w7w2zgr/7MnNKsWNb6rfCY06G9rzEDYs1n5vk4kTDlSICiBWZIbwvq715ijt/mMJv77U6oWHp02jZjjDlWXx3NSefhOLySmKZ9BB1J/Cnrd4wJlDC48lls7V8/Lsuc/k0aQH1sDrUtPlLLFhAXCLuSzh5rjiPlfMqypmA7/CG99z559LlcGeb52xvWa+aIOzZkt6qxpeM2PNgxg5OBrd3zZWI0V2EjiCf766SMf/X456wLFFBERMQUaDY/vGNT4eC7ZsUnd5I5fbXnRfPKOyNgTtcV3n5izxkMmD1AbVOTnS0Oeczj/GaPVmIfs9q16jvmB+llb4AzxQxCno3mtpTzIekcs3qzeqoZAt2DzH6qpELzg9mZduzzb3/arKoN+QmkDO44ZjCXQ9j0CzNw9fmGOZ59b5jhMj7XfP6sSzs+b1MllL1mTuUlFrTed9gMf8kDIeufws55k1mBSrvQnOoFOLzKDGhN5TB8tnnVYPh5qy+FdfeZPWTZXzOnZjMvPrYSWrsTDiw2w965M8xer2WTzZ+z/gkq3jfDZ1w2XL4Idv2XGeJyiqHgBnNcLdXm/u7BQBB2Pmve2vrMcorhvPvN4HgKKaCIiMiZwzDMfq+kAeDo+mXTUcMwzKpdd1dOGyvMikr+v0BS/xN/XKAFDq2A+HxIGdQtQ+vK57e+sU1ERKKbzdaxGnK6stnMaaLuFp8Ng+7v+uMcTrNyEiVOsC4nIiIi0nMsDSjz5s2jX79+xMXFMXbsWD7++GMrhyMiIiJRwrKA8vLLL/Pggw/yyCOPsH79eoYPH87EiROprKw8/oNFRETkjGZZQHniiSe4++67ueuuuxgyZAjz588nISGB//7v/7ZqSCIiIhIlLAkoLS0trFu3juLio804drud4uJiSkpKjtm/ubkZr9fb4SYiIiJnLksCyuHDhwkEAmRnZ3e4Pzs7m/Ly8mP2nz17NikpKaFbQUFBTw1VRERELHBaXMUzc+ZMPB5P6FZWVnb8B4mIiMhpy5J1UDIzM3E4HFRUdPxm1IqKCnJyco7Z3+Vy4XJ9xe//EBERkdOGJRUUp9PJyJEjWbp0aei+YDDI0qVLKSoqsmJIIiIiEkUsW0n2wQcf5M4772TUqFGMGTOGp556ivr6eu666y6rhiQiIiJRwrKAcvPNN3Po0CFmzZpFeXk5F154IYsXLz6mcVZERETOPvqyQBEREekRXfn8Pi2u4hEREZGzy2n5bcZtRR8t2CYiInL6aPvcPpHJm9MyoNTW1gJowTYREZHTUG1tLSkpKV+6z2nZgxIMBjlw4ADJycnYbLZT+txer5eCggLKysrU39INdH67l85v99M57l46v93PynNsGAa1tbXk5eVht395l8lpWUGx2+3k5+d362u43W79x9GNdH67l85v99M57l46v93PqnN8vMpJGzXJioiISNRRQBEREZGoo4ASxuVy8cgjj+i7f7qJzm/30vntfjrH3Uvnt/udLuf4tGySFRERkTObKigiIiISdRRQREREJOoooIiIiEjUUUARERGRqKOA0s68efPo168fcXFxjB07lo8//tjqIZ2Wfvazn2Gz2TrcBg0aFNre1NTE9OnTycjIICkpiRtvvJGKigoLRxz9VqxYwbXXXkteXh42m43XX3+9w3bDMJg1axa5ubnEx8dTXFzMjh07OuxTVVXFlClTcLvdpKamMnXqVOrq6nrwKKLX8c7vt7/97WPe05MmTeqwj85v52bPns3o0aNJTk4mKyuL66+/nm3btnXY50R+L5SWljJ58mQSEhLIysrioYcewu/39+ShRK0TOcdXXHHFMe/je+65p8M+0XSOFVBavfzyyzz44IM88sgjrF+/nuHDhzNx4kQqKyutHtpp6fzzz+fgwYOh24cffhja9sADD/Dmm2/yyiuvsHz5cg4cOMANN9xg4WijX319PcOHD2fevHkRt8+ZM4e5c+cyf/58Vq9eTWJiIhMnTqSpqSm0z5QpU9i0aRNLlixh0aJFrFixgmnTpvXUIUS1451fgEmTJnV4T7/00ksdtuv8dm758uVMnz6dVatWsWTJEnw+HxMmTKC+vj60z/F+LwQCASZPnkxLSwsrV65k4cKFLFiwgFmzZllxSFHnRM4xwN13393hfTxnzpzQtqg7x4YYhmEYY8aMMaZPnx76ORAIGHl5ecbs2bMtHNXp6ZFHHjGGDx8ecVtNTY0RGxtrvPLKK6H7tmzZYgBGSUlJD43w9AYYr732WujnYDBo5OTkGL/5zW9C99XU1Bgul8t46aWXDMMwjM2bNxuAsWbNmtA+b7/9tmGz2Yz9+/f32NhPB+Hn1zAM48477zSuu+66Th+j89s1lZWVBmAsX77cMIwT+73w1ltvGXa73SgvLw/t88wzzxhut9tobm7u2QM4DYSfY8MwjMsvv9y47777On1MtJ1jVVCAlpYW1q1bR3Fxceg+u91OcXExJSUlFo7s9LVjxw7y8vLo378/U6ZMobS0FIB169bh8/k6nOtBgwbRp08fneuTtHv3bsrLyzuc05SUFMaOHRs6pyUlJaSmpjJq1KjQPsXFxdjtdlavXt3jYz4dLVu2jKysLM477zzuvfdejhw5Etqm89s1Ho8HgPT0dODEfi+UlJQwbNgwsrOzQ/tMnDgRr9fLpk2benD0p4fwc9zmhRdeIDMzk6FDhzJz5kwaGhpC26LtHJ+WXxZ4qh0+fJhAINDhHwUgOzubrVu3WjSq09fYsWNZsGAB5513HgcPHuTRRx/ln/7pn9i4cSPl5eU4nU5SU1M7PCY7O5vy8nJrBnyaaztvkd6/bdvKy8vJysrqsD0mJob09HSd9xMwadIkbrjhBgoLC9m1axf//u//zlVXXUVJSQkOh0PntwuCwSD3338/l1xyCUOHDgU4od8L5eXlEd/jbdvkqEjnGOC2226jb9++5OXl8fnnn/PjH/+Ybdu28eqrrwLRd44VUOSUu+qqq0J/v+CCCxg7dix9+/blL3/5C/Hx8RaOTOTk3HLLLaG/Dxs2jAsuuIABAwawbNkyxo8fb+HITj/Tp09n48aNHfrS5NTq7By374kaNmwYubm5jB8/nl27djFgwICeHuZxaYoHyMzMxOFwHNMxXlFRQU5OjkWjOnOkpqZy7rnnsnPnTnJycmhpaaGmpqbDPjrXJ6/tvH3Z+zcnJ+eYhm+/309VVZXO+0no378/mZmZ7Ny5E9D5PVEzZsxg0aJFvP/+++Tn54fuP5HfCzk5ORHf423bxNTZOY5k7NixAB3ex9F0jhVQAKfTyciRI1m6dGnovmAwyNKlSykqKrJwZGeGuro6du3aRW5uLiNHjiQ2NrbDud62bRulpaU61yepsLCQnJycDufU6/WyevXq0DktKiqipqaGdevWhfZ57733CAaDoV9ScuL27dvHkSNHyM3NBXR+j8cwDGbMmMFrr73Ge++9R2FhYYftJ/J7oaioiA0bNnQIgkuWLMHtdjNkyJCeOZAodrxzHMmnn34K0OF9HFXnuMfbcqPUn//8Z8PlchkLFiwwNm/ebEybNs1ITU3t0M0sJ+YHP/iBsWzZMmP37t3GRx99ZBQXFxuZmZlGZWWlYRiGcc899xh9+vQx3nvvPWPt2rVGUVGRUVRUZPGoo1ttba3xySefGJ988okBGE888YTxySefGHv37jUMwzB+9atfGampqcYbb7xhfP7558Z1111nFBYWGo2NjaHnmDRpkjFixAhj9erVxocffmgMHDjQuPXWW606pKjyZee3trbW+OEPf2iUlJQYu3fvNv7xj38YF110kTFw4ECjqakp9Bw6v5279957jZSUFGPZsmXGwYMHQ7eGhobQPsf7veD3+42hQ4caEyZMMD799FNj8eLFRq9evYyZM2dacUhR53jneOfOncZjjz1mrF271ti9e7fxxhtvGP379zcuu+yy0HNE2zlWQGnn6aefNvr06WM4nU5jzJgxxqpVq6we0mnp5ptvNnJzcw2n02n07t3buPnmm42dO3eGtjc2Nhrf+973jLS0NCMhIcH4+te/bhw8eNDCEUe/999/3wCOud15552GYZiXGj/88MNGdna24XK5jPHjxxvbtm3r8BxHjhwxbr31ViMpKclwu93GXXfdZdTW1lpwNNHny85vQ0ODMWHCBKNXr15GbGys0bdvX+Puu+8+5n9edH47F+ncAsbzzz8f2udEfi/s2bPHuOqqq4z4+HgjMzPT+MEPfmD4fL4ePprodLxzXFpaalx22WVGenq64XK5jHPOOcd46KGHDI/H0+F5oukc2wzDMHquXiMiIiJyfOpBERERkaijgCIiIiJRRwFFREREoo4CioiIiEQdBRQRERGJOgooIiIiEnUUUERERCTqKKCIiIhI1FFAERERkaijgCIiIiJRRwFFREREoo4CioiIiESd/w8q3ShzIiKZUQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.evaluate(np.array(x_test), np.array(y_test), verbose=2)\n",
        "\n",
        "print(\"Trained model, loss: {:5.2f}\".format(loss))\n",
        "# print(\"Trained model, accuracy: {:5.2f}%\".format(100-loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw7xOuQXaPH5",
        "outputId": "23f4c09c-3166-4f8f-8cda-102f3ae4830e"
      },
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 0s - loss: 12.6623 - 40ms/epoch - 20ms/step\n",
            "Trained model, loss: 12.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [None] * 463\n",
        "y = [None] * 463\n",
        "for i in range(463):\n",
        "  x[i] = img_tensors[i]\n",
        "  y[i] = front_tensors[i]\n",
        "\n",
        "idk = model.evaluate(np.array(x), np.array(y), verbose=2)\n",
        "\n",
        "print(\"Trained model, loss: {:5.2f}\".format(idk))\n",
        "# print(\"Trained model, accuracy: {:5.2f}%\".format(100-loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDlF9lvqhbFq",
        "outputId": "4ed1f7ae-0377-4886-f2de-d994e8998ee3"
      },
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 - 0s - loss: 13.9454 - 62ms/epoch - 4ms/step\n",
            "Trained model, loss: 13.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = model.predict(np.array(x))\n",
        "n = 450\n",
        "print(example[n])\n",
        "print(y[n])\n",
        "print(abs(example[n]-y[n]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnfdsFYrafF8",
        "outputId": "65a4da87-ddfc-4f8d-83b2-9bdf1eac05f7"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 6ms/step\n",
            "[308.46872]\n",
            "[314]\n",
            "[5.53128052]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('kerasLionfront.pb')"
      ],
      "metadata": {
        "id": "DkmI23JoesE0"
      },
      "execution_count": 530,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_train = [None] * train_len\n",
        "\n",
        "z_val = [None] * val_len\n",
        "\n",
        "z_test = [None] * test_len\n",
        "\n",
        "\n",
        "for i in range(train_len):\n",
        "  z_train[i] = back_tensors[i]\n",
        "\n",
        "for i in range(val_len):\n",
        "  z_val[i] = back_tensors[i + train_len]\n",
        "\n",
        "for i in range(test_len):\n",
        "  z_test[i] = back_tensors[i+ train_len + val_len]\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "    layers.Dense(units = 512, activation = 'relu', input_shape = [1280]),\n",
        "    layers.Dense(units = 256, activation = 'relu'),\n",
        "    layers.Dense(units = 1)\n",
        "])\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer = keras.optimizers.Lion(learning_rate = 0.0005, use_ema = True),\n",
        "    loss = \"mean_absolute_error\",\n",
        ")\n",
        "\n",
        "history_2 = model_2.fit(\n",
        "    np.array(x_train), np.array(z_train),\n",
        "    validation_data = [np.array(x_val), np.array(z_val)],\n",
        "    epochs= 256,\n",
        "    batch_size= 64,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp3OFTb0ilbq",
        "outputId": "2e4ff0d2-19de-4199-ec1d-8b41aa1832b7"
      },
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "6/6 [==============================] - 1s 45ms/step - loss: 955.1912 - val_loss: 775.5683\n",
            "Epoch 2/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 514.2798 - val_loss: 453.2200\n",
            "Epoch 3/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 322.8073 - val_loss: 279.0292\n",
            "Epoch 4/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 234.8783 - val_loss: 213.7377\n",
            "Epoch 5/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 185.4036 - val_loss: 163.3152\n",
            "Epoch 6/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 144.0358 - val_loss: 190.9109\n",
            "Epoch 7/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 140.5919 - val_loss: 124.9051\n",
            "Epoch 8/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 121.7442 - val_loss: 125.2768\n",
            "Epoch 9/256\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 126.0137 - val_loss: 121.9078\n",
            "Epoch 10/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 114.5126 - val_loss: 112.3364\n",
            "Epoch 11/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 120.3232 - val_loss: 114.2230\n",
            "Epoch 12/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 111.2643 - val_loss: 104.8041\n",
            "Epoch 13/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 115.4008 - val_loss: 101.8828\n",
            "Epoch 14/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 104.9050 - val_loss: 92.2483\n",
            "Epoch 15/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 95.8660 - val_loss: 82.4701\n",
            "Epoch 16/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 93.3050 - val_loss: 79.9675\n",
            "Epoch 17/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 87.1383 - val_loss: 90.6784\n",
            "Epoch 18/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 94.3130 - val_loss: 81.2448\n",
            "Epoch 19/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 83.1260 - val_loss: 71.5777\n",
            "Epoch 20/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 83.7592 - val_loss: 54.8466\n",
            "Epoch 21/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 81.1290 - val_loss: 64.8621\n",
            "Epoch 22/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 85.2033 - val_loss: 65.3733\n",
            "Epoch 23/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 79.0691 - val_loss: 65.3446\n",
            "Epoch 24/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 72.8362 - val_loss: 71.0634\n",
            "Epoch 25/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 74.6452 - val_loss: 71.0399\n",
            "Epoch 26/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 73.5488 - val_loss: 63.9284\n",
            "Epoch 27/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 70.5189 - val_loss: 61.7601\n",
            "Epoch 28/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 64.3061 - val_loss: 71.7064\n",
            "Epoch 29/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 68.6512 - val_loss: 60.4811\n",
            "Epoch 30/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 65.3625 - val_loss: 59.9634\n",
            "Epoch 31/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 65.6151 - val_loss: 56.1454\n",
            "Epoch 32/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 57.0746 - val_loss: 41.6085\n",
            "Epoch 33/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 62.1964 - val_loss: 58.6779\n",
            "Epoch 34/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 63.2078 - val_loss: 55.4113\n",
            "Epoch 35/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 58.9971 - val_loss: 53.9485\n",
            "Epoch 36/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 60.7425 - val_loss: 55.2351\n",
            "Epoch 37/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 56.5967 - val_loss: 50.7416\n",
            "Epoch 38/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 61.9857 - val_loss: 49.7664\n",
            "Epoch 39/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 60.5147 - val_loss: 54.5264\n",
            "Epoch 40/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 59.1265 - val_loss: 58.3380\n",
            "Epoch 41/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 60.0515 - val_loss: 57.5612\n",
            "Epoch 42/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 57.8851 - val_loss: 55.3180\n",
            "Epoch 43/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 58.0064 - val_loss: 49.5991\n",
            "Epoch 44/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 58.0007 - val_loss: 51.3318\n",
            "Epoch 45/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 53.5894 - val_loss: 57.8115\n",
            "Epoch 46/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 54.9798 - val_loss: 51.3204\n",
            "Epoch 47/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 54.7461 - val_loss: 46.4358\n",
            "Epoch 48/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 56.0579 - val_loss: 46.6901\n",
            "Epoch 49/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 52.9447 - val_loss: 46.7982\n",
            "Epoch 50/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 53.6908 - val_loss: 58.4030\n",
            "Epoch 51/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 53.6488 - val_loss: 59.1154\n",
            "Epoch 52/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 54.8862 - val_loss: 51.6680\n",
            "Epoch 53/256\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 52.9004 - val_loss: 53.0951\n",
            "Epoch 54/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 52.6902 - val_loss: 54.3958\n",
            "Epoch 55/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 49.9010 - val_loss: 53.7310\n",
            "Epoch 56/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 50.0524 - val_loss: 53.6553\n",
            "Epoch 57/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 51.3038 - val_loss: 49.0541\n",
            "Epoch 58/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 49.8725 - val_loss: 52.1254\n",
            "Epoch 59/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 49.9691 - val_loss: 46.8655\n",
            "Epoch 60/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 52.1300 - val_loss: 42.7708\n",
            "Epoch 61/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 49.9486 - val_loss: 44.8311\n",
            "Epoch 62/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 49.3845 - val_loss: 44.2714\n",
            "Epoch 63/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 47.6270 - val_loss: 47.9692\n",
            "Epoch 64/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 49.7334 - val_loss: 43.8439\n",
            "Epoch 65/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 47.9125 - val_loss: 44.9853\n",
            "Epoch 66/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 47.3627 - val_loss: 44.5298\n",
            "Epoch 67/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 47.6786 - val_loss: 49.8375\n",
            "Epoch 68/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 51.1717 - val_loss: 46.5251\n",
            "Epoch 69/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 44.9029 - val_loss: 50.2212\n",
            "Epoch 70/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 45.8369 - val_loss: 48.0618\n",
            "Epoch 71/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 46.1993 - val_loss: 51.9607\n",
            "Epoch 72/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 48.5836 - val_loss: 42.9594\n",
            "Epoch 73/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 48.8174 - val_loss: 42.3615\n",
            "Epoch 74/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 47.6437 - val_loss: 42.1279\n",
            "Epoch 75/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 42.5019 - val_loss: 40.6787\n",
            "Epoch 76/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 47.1993 - val_loss: 38.9913\n",
            "Epoch 77/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 44.9941 - val_loss: 39.9472\n",
            "Epoch 78/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 43.0946 - val_loss: 36.4988\n",
            "Epoch 79/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 45.7392 - val_loss: 37.0253\n",
            "Epoch 80/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 39.2667 - val_loss: 34.9039\n",
            "Epoch 81/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.5480 - val_loss: 35.9546\n",
            "Epoch 82/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 42.2787 - val_loss: 38.2101\n",
            "Epoch 83/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 43.6463 - val_loss: 40.8799\n",
            "Epoch 84/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 43.3035 - val_loss: 38.5886\n",
            "Epoch 85/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 44.1110 - val_loss: 39.0091\n",
            "Epoch 86/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.0695 - val_loss: 38.1378\n",
            "Epoch 87/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 44.3847 - val_loss: 39.8232\n",
            "Epoch 88/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 41.4547 - val_loss: 42.6707\n",
            "Epoch 89/256\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 40.5610 - val_loss: 36.7114\n",
            "Epoch 90/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.9752 - val_loss: 38.1659\n",
            "Epoch 91/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 41.7129 - val_loss: 39.9146\n",
            "Epoch 92/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.4998 - val_loss: 41.8902\n",
            "Epoch 93/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 41.6036 - val_loss: 37.2430\n",
            "Epoch 94/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.0752 - val_loss: 35.4288\n",
            "Epoch 95/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.4748 - val_loss: 39.1592\n",
            "Epoch 96/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 43.2336 - val_loss: 38.7410\n",
            "Epoch 97/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.1984 - val_loss: 39.8572\n",
            "Epoch 98/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.0855 - val_loss: 36.6728\n",
            "Epoch 99/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 37.4960 - val_loss: 33.9132\n",
            "Epoch 100/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.0567 - val_loss: 30.9216\n",
            "Epoch 101/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.6135 - val_loss: 32.8821\n",
            "Epoch 102/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 39.8652 - val_loss: 34.6730\n",
            "Epoch 103/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.8291 - val_loss: 35.3557\n",
            "Epoch 104/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 39.1480 - val_loss: 33.0682\n",
            "Epoch 105/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 38.8957 - val_loss: 37.4806\n",
            "Epoch 106/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 41.9055 - val_loss: 39.0226\n",
            "Epoch 107/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 39.2421 - val_loss: 36.7853\n",
            "Epoch 108/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 41.0772 - val_loss: 37.9531\n",
            "Epoch 109/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 39.8255 - val_loss: 36.8843\n",
            "Epoch 110/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 37.9518 - val_loss: 38.0287\n",
            "Epoch 111/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 39.1827 - val_loss: 41.2372\n",
            "Epoch 112/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.5686 - val_loss: 40.1798\n",
            "Epoch 113/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 38.3357 - val_loss: 42.3428\n",
            "Epoch 114/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 37.6304 - val_loss: 41.1234\n",
            "Epoch 115/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 39.3933 - val_loss: 39.5596\n",
            "Epoch 116/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 37.8287 - val_loss: 37.8124\n",
            "Epoch 117/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 39.2178 - val_loss: 35.4318\n",
            "Epoch 118/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 37.3278 - val_loss: 34.0918\n",
            "Epoch 119/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 37.0473 - val_loss: 33.3254\n",
            "Epoch 120/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 37.8257 - val_loss: 30.8814\n",
            "Epoch 121/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 36.4125 - val_loss: 31.5542\n",
            "Epoch 122/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 38.3635 - val_loss: 34.8803\n",
            "Epoch 123/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 37.9499 - val_loss: 33.1577\n",
            "Epoch 124/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 35.9942 - val_loss: 32.3920\n",
            "Epoch 125/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 35.8269 - val_loss: 40.4368\n",
            "Epoch 126/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 39.5576 - val_loss: 39.3216\n",
            "Epoch 127/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 38.6489 - val_loss: 37.2000\n",
            "Epoch 128/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 38.7490 - val_loss: 37.0493\n",
            "Epoch 129/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 37.1441 - val_loss: 33.0496\n",
            "Epoch 130/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 37.4349 - val_loss: 34.2981\n",
            "Epoch 131/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 37.4843 - val_loss: 35.8803\n",
            "Epoch 132/256\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 37.0521 - val_loss: 37.6927\n",
            "Epoch 133/256\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 38.2881 - val_loss: 39.7657\n",
            "Epoch 134/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 37.7722 - val_loss: 49.4084\n",
            "Epoch 135/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 36.0599 - val_loss: 44.4829\n",
            "Epoch 136/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 36.3567 - val_loss: 45.3973\n",
            "Epoch 137/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.6475 - val_loss: 42.6974\n",
            "Epoch 138/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 38.2429 - val_loss: 41.4090\n",
            "Epoch 139/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 36.1460 - val_loss: 40.5340\n",
            "Epoch 140/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.3970 - val_loss: 40.7697\n",
            "Epoch 141/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.0116 - val_loss: 33.3971\n",
            "Epoch 142/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 37.4575 - val_loss: 34.0050\n",
            "Epoch 143/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 36.5017 - val_loss: 31.5440\n",
            "Epoch 144/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 36.7148 - val_loss: 35.9621\n",
            "Epoch 145/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.7387 - val_loss: 33.7120\n",
            "Epoch 146/256\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 36.7530 - val_loss: 33.9598\n",
            "Epoch 147/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 41.0475 - val_loss: 35.2119\n",
            "Epoch 148/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 37.1127 - val_loss: 33.3908\n",
            "Epoch 149/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.6323 - val_loss: 31.2141\n",
            "Epoch 150/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 37.1980 - val_loss: 35.0609\n",
            "Epoch 151/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 37.5834 - val_loss: 32.0697\n",
            "Epoch 152/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.6078 - val_loss: 35.4983\n",
            "Epoch 153/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 39.5983 - val_loss: 32.0616\n",
            "Epoch 154/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 36.6245 - val_loss: 31.8384\n",
            "Epoch 155/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.6253 - val_loss: 36.8266\n",
            "Epoch 156/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.0843 - val_loss: 37.4990\n",
            "Epoch 157/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 36.8906 - val_loss: 41.4351\n",
            "Epoch 158/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.2482 - val_loss: 38.2134\n",
            "Epoch 159/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.1812 - val_loss: 35.4202\n",
            "Epoch 160/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.7293 - val_loss: 38.8077\n",
            "Epoch 161/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.0887 - val_loss: 40.7613\n",
            "Epoch 162/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.9294 - val_loss: 28.8595\n",
            "Epoch 163/256\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 34.2697 - val_loss: 33.1591\n",
            "Epoch 164/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.6615 - val_loss: 33.3797\n",
            "Epoch 165/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.6973 - val_loss: 38.6539\n",
            "Epoch 166/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.7440 - val_loss: 36.8678\n",
            "Epoch 167/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 36.1494 - val_loss: 42.1896\n",
            "Epoch 168/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.2602 - val_loss: 42.2326\n",
            "Epoch 169/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 36.5455 - val_loss: 38.4286\n",
            "Epoch 170/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.3154 - val_loss: 37.6996\n",
            "Epoch 171/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 33.9505 - val_loss: 40.6188\n",
            "Epoch 172/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.1963 - val_loss: 38.1296\n",
            "Epoch 173/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 34.1044 - val_loss: 41.6871\n",
            "Epoch 174/256\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 36.2225 - val_loss: 40.3166\n",
            "Epoch 175/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 34.3996 - val_loss: 34.5880\n",
            "Epoch 176/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 35.6094 - val_loss: 32.6253\n",
            "Epoch 177/256\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 35.4025 - val_loss: 33.9362\n",
            "Epoch 178/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 35.9627 - val_loss: 34.4497\n",
            "Epoch 179/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 37.5747 - val_loss: 33.9707\n",
            "Epoch 180/256\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 36.1752 - val_loss: 34.3985\n",
            "Epoch 181/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 35.8297 - val_loss: 36.0028\n",
            "Epoch 182/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 34.1062 - val_loss: 35.0284\n",
            "Epoch 183/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 35.8672 - val_loss: 34.9022\n",
            "Epoch 184/256\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 35.3817 - val_loss: 36.6447\n",
            "Epoch 185/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 33.5140 - val_loss: 36.3467\n",
            "Epoch 186/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 35.2017 - val_loss: 34.6294\n",
            "Epoch 187/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 34.3101 - val_loss: 37.3860\n",
            "Epoch 188/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 34.0667 - val_loss: 35.6740\n",
            "Epoch 189/256\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 34.7210 - val_loss: 37.3270\n",
            "Epoch 190/256\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 34.5274 - val_loss: 42.0398\n",
            "Epoch 191/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 35.4482 - val_loss: 38.2665\n",
            "Epoch 192/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 35.0130 - val_loss: 30.3406\n",
            "Epoch 193/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 32.9908 - val_loss: 38.8854\n",
            "Epoch 194/256\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 33.1605 - val_loss: 39.9112\n",
            "Epoch 195/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 32.1549 - val_loss: 39.6955\n",
            "Epoch 196/256\n",
            "6/6 [==============================] - 0s 66ms/step - loss: 31.3157 - val_loss: 29.6302\n",
            "Epoch 197/256\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 35.4493 - val_loss: 27.7699\n",
            "Epoch 198/256\n",
            "6/6 [==============================] - 0s 66ms/step - loss: 33.5275 - val_loss: 36.4898\n",
            "Epoch 199/256\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 32.6147 - val_loss: 38.1967\n",
            "Epoch 200/256\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 32.6847 - val_loss: 41.5707\n",
            "Epoch 201/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 32.1882 - val_loss: 38.6534\n",
            "Epoch 202/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 31.1279 - val_loss: 37.5208\n",
            "Epoch 203/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 31.9553 - val_loss: 40.2336\n",
            "Epoch 204/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 33.7808 - val_loss: 36.5577\n",
            "Epoch 205/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 33.2604 - val_loss: 33.7371\n",
            "Epoch 206/256\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 32.5192 - val_loss: 34.4897\n",
            "Epoch 207/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 31.6259 - val_loss: 38.7806\n",
            "Epoch 208/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 34.6000 - val_loss: 37.9490\n",
            "Epoch 209/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 32.8446 - val_loss: 34.2739\n",
            "Epoch 210/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 34.6352 - val_loss: 35.5015\n",
            "Epoch 211/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 33.3970 - val_loss: 33.4591\n",
            "Epoch 212/256\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 32.8049 - val_loss: 32.8624\n",
            "Epoch 213/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 31.6866 - val_loss: 37.8611\n",
            "Epoch 214/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 30.4208 - val_loss: 37.8499\n",
            "Epoch 215/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 31.5651 - val_loss: 41.4531\n",
            "Epoch 216/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 33.7740 - val_loss: 42.8708\n",
            "Epoch 217/256\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 31.3635 - val_loss: 41.9547\n",
            "Epoch 218/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 33.9114 - val_loss: 29.7669\n",
            "Epoch 219/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 31.6092 - val_loss: 32.5988\n",
            "Epoch 220/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 32.7834 - val_loss: 32.7053\n",
            "Epoch 221/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 32.2262 - val_loss: 33.5774\n",
            "Epoch 222/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 31.0790 - val_loss: 35.1091\n",
            "Epoch 223/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 33.0380 - val_loss: 36.5380\n",
            "Epoch 224/256\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 32.9787 - val_loss: 35.7472\n",
            "Epoch 225/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 32.3099 - val_loss: 35.1351\n",
            "Epoch 226/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 30.3329 - val_loss: 36.8886\n",
            "Epoch 227/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 32.4544 - val_loss: 35.3297\n",
            "Epoch 228/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.9022 - val_loss: 35.9036\n",
            "Epoch 229/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 31.9298 - val_loss: 34.4184\n",
            "Epoch 230/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 29.9143 - val_loss: 34.0485\n",
            "Epoch 231/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.5057 - val_loss: 36.1435\n",
            "Epoch 232/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 33.3422 - val_loss: 34.2774\n",
            "Epoch 233/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 34.3807 - val_loss: 32.9314\n",
            "Epoch 234/256\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 31.9810 - val_loss: 33.4769\n",
            "Epoch 235/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.7933 - val_loss: 31.9091\n",
            "Epoch 236/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 30.2974 - val_loss: 37.2961\n",
            "Epoch 237/256\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 30.6871 - val_loss: 33.0108\n",
            "Epoch 238/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 31.3693 - val_loss: 36.2160\n",
            "Epoch 239/256\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 33.2915 - val_loss: 37.2946\n",
            "Epoch 240/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 31.6941 - val_loss: 39.7516\n",
            "Epoch 241/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 28.6677 - val_loss: 39.8501\n",
            "Epoch 242/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 33.0840 - val_loss: 38.0435\n",
            "Epoch 243/256\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 31.2484 - val_loss: 33.4289\n",
            "Epoch 244/256\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 33.4478 - val_loss: 29.2130\n",
            "Epoch 245/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 31.8522 - val_loss: 30.2856\n",
            "Epoch 246/256\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 30.6455 - val_loss: 31.3897\n",
            "Epoch 247/256\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 30.1235 - val_loss: 32.4397\n",
            "Epoch 248/256\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 31.1526 - val_loss: 34.1231\n",
            "Epoch 249/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 30.8841 - val_loss: 39.1376\n",
            "Epoch 250/256\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 33.5432 - val_loss: 38.4611\n",
            "Epoch 251/256\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 34.9818 - val_loss: 36.7821\n",
            "Epoch 252/256\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 33.1490 - val_loss: 27.6819\n",
            "Epoch 253/256\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 30.3346 - val_loss: 26.9456\n",
            "Epoch 254/256\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.0047 - val_loss: 27.6639\n",
            "Epoch 255/256\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 31.5804 - val_loss: 27.8958\n",
            "Epoch 256/256\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.3095 - val_loss: 29.9792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_2.history['loss'], color = 'teal', label = 'loss')\n",
        "plt.plot(history_2.history['val_loss'], color = 'orange', label = 'val_loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "7X6bodgxoIia",
        "outputId": "60d213d6-aa06-48c6-d97c-e10cc2469fd8"
      },
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_2 = model_2.evaluate(np.array(x_test), np.array(z_test), verbose=2)\n",
        "\n",
        "print(\"Trained model, loss: {:5.2f}\".format(loss_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBwm_mKXq8Wn",
        "outputId": "0c4ad4e6-fd0d-4169-fd88-4db0defb8530"
      },
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 0s - loss: 13.6656 - 37ms/epoch - 19ms/step\n",
            "Trained model, loss: 13.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save('kerasLionback.pb')"
      ],
      "metadata": {
        "id": "jwLMco5E989Z"
      },
      "execution_count": 531,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('kerasLionfront.pb')"
      ],
      "metadata": {
        "id": "_rZDrTSSGI_W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}